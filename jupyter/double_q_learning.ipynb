{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t52,\n",
    "\t\t\t10,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayer = nn.Linear(prev_size, cur_size)\n",
    "\t\t\tnn.init.kaiming_uniform(layer.weight, nonlinearity='relu')\n",
    "\t\t\tlayers.append(layer)\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(device)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer, current_step: int) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\twe_captured = state.make_move(*action) * cur_sign\n",
    "\tenemy_captured = 0\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\tenemy_captured += state.make_move(*enemy.decide_move(state)) * cur_sign * (-1)\n",
    "\n",
    "\treward = 3*(we_captured - enemy_captured)\n",
    "\t# if current_step > 10 and not we_captured:\n",
    "\t# \treward -= 2\n",
    "\t\t\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([next_state.make_move(s, e) * next_state.turn_sign], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_312304\\2008860337.py:28: FutureWarning: `nn.init.kaiming_uniform` is now deprecated in favor of `nn.init.kaiming_uniform_`.\n",
      "  nn.init.kaiming_uniform(layer.weight, nonlinearity='relu')\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.9 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005 # update rate\n",
    "LR = 1e-4 # AdamW learning rate\n",
    "\n",
    "policy_net = DQN().to(device) # to be updated often\n",
    "target_net = DQN().to(device) # to be updated with TAU\n",
    "# policy_net.load_state_dict(torch.load(\"dqn80.pth\"))\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(policy_net, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransitionRecord:\n",
    "\tcurrent_state: Board\n",
    "\tnext_state: Board\n",
    "\timmediate_reward: torch.Tensor\n",
    "\n",
    "def optimize_model(memory: list[TransitionRecord]):\n",
    "\tif len(memory) < BATCH_SIZE:\n",
    "\t\treturn\n",
    "\t\n",
    "\tstate_action_values = []\n",
    "\texpected_state_action_values = []\n",
    "\n",
    "\tfor r in random.sample(memory, BATCH_SIZE):\n",
    "\t\t# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "\t\t# columns of actions taken. These are the actions which would've been taken\n",
    "\t\t# for each batch state according to policy_net\n",
    "\t\tstate_action_values.append(\n",
    "\t\t\tmax(q_s(policy_net, r.current_state), key=lambda x: x.value.item()).value\n",
    "\t\t)\n",
    "\n",
    "\t\tnext_state_value = 0\n",
    "\t\tif r.next_state.game_state == GameState.NOT_OVER:\n",
    "\t\t\tnext_state_action = max(q_s(policy_net, r.next_state), key=lambda x: x.value.item()).action\n",
    "\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tnext_state_value = next(a.value for a in q_s(target_net, r.next_state) if a.action == next_state_action)\n",
    "\t\t# Compute the expected Q values\n",
    "\t\texpected_state_action_values.append((next_state_value * GAMMA) + r.immediate_reward)\n",
    "\n",
    "\t# Compute Huber loss\n",
    "\tcriterion = nn.SmoothL1Loss()\n",
    "\tloss = criterion(\n",
    "\t\ttorch.cat(state_action_values),\n",
    "\t\ttorch.cat(expected_state_action_values)\n",
    "\t)\n",
    "\n",
    "\t# Optimize the model\n",
    "\toptimizer.zero_grad()\n",
    "\tloss.backward()\n",
    "\t# In-place gradient clipping\n",
    "\ttorch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "\toptimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(net: DQN) -> int:\n",
    "\tenemy = RandomPlayer(random.randint(0, 10000))\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\n",
    "\treturn (1 if board.game_state == GameState(-1) else -1) * pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "backup = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 finished. 0/20 | 11/20  8.0\n",
      "Episode 1 finished. 0/20 | 12/20  9.0\n",
      "Episode 2 finished. 0/20 | 10/20  11.666666666666666\n",
      "Episode 3 finished. 0/20 | 12/20  13.0\n",
      "Episode 4 finished. 0/20 | 11/20  14.8\n",
      "Episode 5 finished. 0/20 | 13/20  14.166666666666666\n",
      "Episode 6 finished. 1/20 | 15/20  13.714285714285714\n",
      "Episode 7 finished. 1/20 | 13/20  15.5\n",
      "Episode 8 finished. 1/20 | 15/20  15.11111111111111\n",
      "Episode 9 finished. 1/20 | 13/20  14.6\n",
      "Episode 10 finished. 2/20 | 14/20  14.090909090909092\n",
      "Episode 11 finished. 3/20 | 11/20  14.5\n",
      "Episode 12 finished. 3/20 | 17/20  14.692307692307692\n",
      "Episode 13 finished. 3/20 | 12/20  16.285714285714285\n",
      "Episode 14 finished. 4/20 | 12/20  15.8\n",
      "Episode 15 finished. 4/20 | 15/20  15.375\n",
      "Episode 16 finished. 4/20 | 14/20  15.352941176470589\n",
      "Episode 17 finished. 5/20 | 16/20  15.222222222222221\n",
      "Episode 18 finished. 5/20 | 9/20  16.210526315789473\n",
      "Episode 19 finished. 5/20 | 12/20  16.15\n",
      "Episode 20 finished. 5/20 | 11/20  15.80952380952381\n",
      "Episode 21 finished. 5/20 | 14/20  15.5\n",
      "Episode 22 finished. 5/20 | 11/20  16.782608695652176\n",
      "Episode 23 finished. 5/20 | 14/20  17.041666666666668\n",
      "Episode 24 finished. 6/20 | 8/20  17.0\n",
      "Episode 25 finished. 7/20 | 14/20  17.03846153846154\n",
      "Episode 26 finished. 7/20 | 9/20  16.88888888888889\n",
      "Episode 27 finished. 7/20 | 10/20  16.642857142857142\n",
      "Episode 28 finished. 7/20 | 13/20  16.344827586206897\n",
      "Episode 29 finished. 7/20 | 11/20  16.4\n",
      "Episode 30 finished. 6/20 | 13/20  16.193548387096776\n",
      "Episode 31 finished. 5/20 | 15/20  16.75\n",
      "Episode 32 finished. 5/20 | 11/20  16.545454545454547\n",
      "Episode 33 finished. 5/20 | 15/20  16.352941176470587\n",
      "Episode 34 finished. 4/20 | 12/20  16.17142857142857\n",
      "Episode 35 finished. 4/20 | 13/20  16.02777777777778\n",
      "Episode 36 finished. 4/20 | 11/20  15.837837837837839\n",
      "Episode 37 finished. 4/20 | 12/20  16.05263157894737\n",
      "Episode 38 finished. 5/20 | 12/20  15.897435897435898\n",
      "Episode 39 finished. 5/20 | 12/20  15.75\n",
      "Episode 40 finished. 6/20 | 13/20  15.707317073170731\n",
      "Episode 41 finished. 7/20 | 11/20  15.857142857142858\n",
      "Episode 42 finished. 7/20 | 14/20  15.744186046511627\n",
      "Episode 43 finished. 7/20 | 14/20  16.0\n",
      "Episode 44 finished. 7/20 | 15/20  16.42222222222222\n",
      "Episode 45 finished. 6/20 | 9/20  16.391304347826086\n",
      "Episode 46 finished. 6/20 | 11/20  16.48936170212766\n",
      "Episode 47 finished. 6/20 | 17/20  16.520833333333332\n",
      "Episode 48 finished. 6/20 | 15/20  16.693877551020407\n",
      "Episode 49 finished. 7/20 | 16/20  16.8\n",
      "Episode 50 finished. 8/20 | 16/20  16.686274509803923\n",
      "Episode 51 finished. 9/20 | 13/20  16.576923076923077\n",
      "Episode 52 finished. 10/20 | 13/20  16.50943396226415\n",
      "Episode 53 finished. 11/20 | 9/20  16.425925925925927\n",
      "Episode 54 finished. 11/20 | 13/20  16.327272727272728\n",
      "Episode 55 finished. 11/20 | 15/20  17.053571428571427\n",
      "Episode 56 finished. 12/20 | 11/20  16.92982456140351\n",
      "Episode 57 finished. 12/20 | 9/20  16.82758620689655\n",
      "Episode 58 finished. 11/20 | 12/20  16.71186440677966\n",
      "Episode 59 finished. 11/20 | 10/20  16.6\n",
      "Episode 60 finished. 10/20 | 13/20  16.491803278688526\n",
      "Episode 61 finished. 10/20 | 8/20  16.43548387096774\n",
      "Episode 62 finished. 10/20 | 13/20  16.746031746031747\n",
      "Episode 63 finished. 10/20 | 11/20  16.609375\n",
      "Episode 64 finished. 10/20 | 11/20  16.876923076923077\n",
      "Episode 65 finished. 10/20 | 12/20  16.757575757575758\n",
      "Episode 66 finished. 10/20 | 14/20  16.83582089552239\n",
      "Episode 67 finished. 11/20 | 10/20  17.029411764705884\n",
      "Episode 68 finished. 12/20 | 14/20  17.043478260869566\n",
      "Episode 69 finished. 11/20 | 14/20  17.32857142857143\n",
      "Episode 70 finished. 11/20 | 14/20  17.225352112676056\n",
      "Episode 71 finished. 10/20 | 11/20  17.11111111111111\n",
      "Episode 72 finished. 9/20 | 13/20  17.45205479452055\n",
      "Episode 73 finished. 8/20 | 12/20  17.54054054054054\n",
      "Episode 74 finished. 8/20 | 13/20  17.76\n",
      "Episode 75 finished. 8/20 | 8/20  17.644736842105264\n",
      "Episode 76 finished. 7/20 | 14/20  17.545454545454547\n",
      "Episode 77 finished. 6/20 | 16/20  18.153846153846153\n",
      "Episode 78 finished. 6/20 | 13/20  18.658227848101266\n",
      "Episode 79 finished. 7/20 | 10/20  18.7625\n",
      "Episode 80 finished. 7/20 | 13/20  19.08641975308642\n",
      "Episode 81 finished. 7/20 | 14/20  19.024390243902438\n",
      "Episode 82 finished. 7/20 | 14/20  19.156626506024097\n",
      "Episode 83 finished. 7/20 | 13/20  19.333333333333332\n",
      "Episode 84 finished. 7/20 | 14/20  19.223529411764705\n",
      "Episode 85 finished. 7/20 | 12/20  19.11627906976744\n",
      "Episode 86 finished. 7/20 | 11/20  19.011494252873565\n",
      "Episode 87 finished. 6/20 | 12/20  19.25\n",
      "Episode 88 finished. 5/20 | 11/20  19.49438202247191\n",
      "Episode 89 finished. 6/20 | 16/20  19.522222222222222\n",
      "Episode 90 finished. 6/20 | 13/20  19.428571428571427\n",
      "Episode 91 finished. 7/20 | 10/20  19.32608695652174\n",
      "Episode 92 finished. 7/20 | 12/20  19.27956989247312\n",
      "Episode 93 finished. 8/20 | 12/20  19.19148936170213\n",
      "Episode 94 finished. 9/20 | 14/20  19.221052631578946\n",
      "Episode 95 finished. 9/20 | 9/20  19.125\n",
      "Episode 96 finished. 9/20 | 12/20  19.309278350515463\n",
      "Episode 97 finished. 9/20 | 8/20  19.214285714285715\n",
      "Episode 98 finished. 10/20 | 11/20  19.141414141414142\n",
      "Episode 99 finished. 10/20 | 10/20  19.04\n",
      "Episode 100 finished. 10/20 | 11/20  19.316831683168317\n",
      "Episode 101 finished. 10/20 | 8/20  19.225490196078432\n",
      "Episode 102 finished. 11/20 | 11/20  19.262135922330096\n",
      "Episode 103 finished. 12/20 | 11/20  19.182692307692307\n",
      "Episode 104 finished. 11/20 | 11/20  19.247619047619047\n",
      "Episode 105 finished. 11/20 | 15/20  19.367924528301888\n",
      "Episode 106 finished. 10/20 | 10/20  19.514018691588785\n",
      "Episode 107 finished. 11/20 | 9/20  19.435185185185187\n",
      "Episode 108 finished. 11/20 | 12/20  19.422018348623855\n",
      "Episode 109 finished. 11/20 | 11/20  19.490909090909092\n",
      "Episode 110 finished. 11/20 | 12/20  19.405405405405407\n",
      "Episode 111 finished. 11/20 | 9/20  19.392857142857142\n",
      "Episode 112 finished. 12/20 | 13/20  19.309734513274336\n",
      "Episode 113 finished. 12/20 | 10/20  19.236842105263158\n",
      "Episode 114 finished. 11/20 | 12/20  19.17391304347826\n",
      "Episode 115 finished. 12/20 | 11/20  19.094827586206897\n",
      "Episode 116 finished. 12/20 | 12/20  19.034188034188034\n",
      "Episode 117 finished. 13/20 | 14/20  18.966101694915253\n",
      "Episode 118 finished. 13/20 | 9/20  18.907563025210084\n",
      "Episode 119 finished. 13/20 | 12/20  18.841666666666665\n",
      "Episode 120 finished. 14/20 | 10/20  18.776859504132233\n",
      "Episode 121 finished. 14/20 | 10/20  18.770491803278688\n",
      "Episode 122 finished. 14/20 | 12/20  18.88617886178862\n",
      "Episode 123 finished. 14/20 | 11/20  18.81451612903226\n",
      "Episode 124 finished. 14/20 | 12/20  18.768\n",
      "Episode 125 finished. 14/20 | 12/20  18.6984126984127\n",
      "Episode 126 finished. 15/20 | 12/20  18.62992125984252\n",
      "Episode 127 finished. 15/20 | 9/20  18.5859375\n",
      "Episode 128 finished. 16/20 | 9/20  18.689922480620154\n",
      "Episode 129 finished. 15/20 | 13/20  18.861538461538462\n",
      "Episode 130 finished. 15/20 | 15/20  18.80916030534351\n",
      "Episode 131 finished. 14/20 | 9/20  18.742424242424242\n",
      "Episode 132 finished. 13/20 | 11/20  18.76691729323308\n",
      "Episode 133 finished. 12/20 | 10/20  18.917910447761194\n",
      "Episode 134 finished. 12/20 | 15/20  19.05185185185185\n",
      "Episode 135 finished. 11/20 | 15/20  18.970588235294116\n",
      "Episode 136 finished. 12/20 | 8/20  18.94160583941606\n",
      "Episode 137 finished. 11/20 | 14/20  19.08695652173913\n",
      "Episode 138 finished. 10/20 | 10/20  19.12230215827338\n",
      "Episode 139 finished. 9/20 | 13/20  19.15714285714286\n",
      "Episode 140 finished. 9/20 | 13/20  19.092198581560282\n",
      "Episode 141 finished. 9/20 | 9/20  19.04225352112676\n",
      "Episode 142 finished. 9/20 | 11/20  18.97902097902098\n",
      "Episode 143 finished. 8/20 | 10/20  18.98611111111111\n",
      "Episode 144 finished. 8/20 | 12/20  19.00689655172414\n",
      "Episode 145 finished. 8/20 | 14/20  19.10958904109589\n",
      "Episode 146 finished. 8/20 | 11/20  19.06122448979592\n",
      "Episode 147 finished. 8/20 | 12/20  19.006756756756758\n",
      "Episode 148 finished. 8/20 | 13/20  18.946308724832214\n",
      "Episode 149 finished. 9/20 | 10/20  19.046666666666667\n",
      "Episode 150 finished. 8/20 | 13/20  19.066225165562916\n",
      "Episode 151 finished. 8/20 | 9/20  19.164473684210527\n",
      "Episode 152 finished. 8/20 | 13/20  19.137254901960784\n",
      "Episode 153 finished. 8/20 | 14/20  19.084415584415584\n",
      "Episode 154 finished. 8/20 | 11/20  19.10322580645161\n",
      "Episode 155 finished. 9/20 | 13/20  19.064102564102566\n",
      "Episode 156 finished. 9/20 | 13/20  19.14012738853503\n",
      "Episode 157 finished. 10/20 | 8/20  19.126582278481013\n",
      "Episode 158 finished. 10/20 | 9/20  19.069182389937108\n",
      "Episode 159 finished. 10/20 | 14/20  19.05625\n",
      "Episode 160 finished. 10/20 | 12/20  19.0\n",
      "Episode 161 finished. 9/20 | 14/20  19.006172839506174\n",
      "Episode 162 finished. 9/20 | 11/20  19.030674846625768\n",
      "Episode 163 finished. 10/20 | 9/20  19.0\n",
      "Episode 164 finished. 11/20 | 11/20  18.98181818181818\n",
      "Episode 165 finished. 12/20 | 14/20  19.132530120481928\n",
      "Episode 166 finished. 12/20 | 12/20  19.077844311377245\n",
      "Episode 167 finished. 12/20 | 11/20  19.029761904761905\n",
      "Episode 168 finished. 12/20 | 11/20  18.976331360946745\n",
      "Episode 169 finished. 11/20 | 5/20  18.91764705882353\n",
      "Episode 170 finished. 11/20 | 15/20  18.95906432748538\n",
      "Episode 171 finished. 12/20 | 10/20  18.912790697674417\n",
      "Episode 172 finished. 13/20 | 14/20  18.86127167630058\n",
      "Episode 173 finished. 13/20 | 14/20  18.810344827586206\n",
      "Episode 174 finished. 14/20 | 13/20  18.8\n",
      "Episode 175 finished. 13/20 | 11/20  18.789772727272727\n",
      "Episode 176 finished. 13/20 | 14/20  18.740112994350284\n",
      "Episode 177 finished. 12/20 | 12/20  18.814606741573034\n",
      "Episode 178 finished. 13/20 | 9/20  18.810055865921786\n",
      "Episode 179 finished. 13/20 | 12/20  18.788888888888888\n",
      "Episode 180 finished. 12/20 | 12/20  18.81767955801105\n",
      "Episode 181 finished. 12/20 | 11/20  18.906593406593405\n",
      "Episode 182 finished. 12/20 | 12/20  18.85792349726776\n",
      "Episode 183 finished. 12/20 | 12/20  18.815217391304348\n",
      "Episode 184 finished. 12/20 | 8/20  18.772972972972973\n",
      "Episode 185 finished. 12/20 | 15/20  18.747311827956988\n",
      "Episode 186 finished. 11/20 | 16/20  18.871657754010695\n",
      "Episode 187 finished. 11/20 | 8/20  18.829787234042552\n",
      "Episode 188 finished. 11/20 | 10/20  18.857142857142858\n",
      "Episode 189 finished. 12/20 | 10/20  18.81578947368421\n",
      "Episode 190 finished. 12/20 | 11/20  18.848167539267017\n",
      "Episode 191 finished. 11/20 | 11/20  18.979166666666668\n",
      "Episode 192 finished. 10/20 | 14/20  18.99481865284974\n",
      "Episode 193 finished. 10/20 | 10/20  19.077319587628867\n",
      "Episode 194 finished. 10/20 | 14/20  19.06153846153846\n",
      "Episode 195 finished. 11/20 | 14/20  19.025510204081634\n",
      "Episode 196 finished. 11/20 | 11/20  19.00507614213198\n",
      "Episode 197 finished. 11/20 | 11/20  19.03030303030303\n",
      "Episode 198 finished. 11/20 | 10/20  19.08040201005025\n",
      "Episode 199 finished. 11/20 | 9/20  19.04\n",
      "Episode 200 finished. 11/20 | 15/20  19.124378109452735\n",
      "Episode 201 finished. 12/20 | 12/20  19.074257425742573\n",
      "Episode 202 finished. 12/20 | 12/20  19.029556650246306\n",
      "Episode 203 finished. 11/20 | 8/20  18.980392156862745\n",
      "Episode 204 finished. 10/20 | 12/20  19.068292682926828\n",
      "Episode 205 finished. 9/20 | 15/20  19.033980582524272\n",
      "Episode 206 finished. 10/20 | 12/20  19.028985507246375\n",
      "Episode 207 finished. 9/20 | 10/20  19.14903846153846\n",
      "Episode 208 finished. 8/20 | 13/20  19.229665071770334\n",
      "Episode 209 finished. 8/20 | 14/20  19.195238095238096\n",
      "Episode 210 finished. 9/20 | 12/20  19.203791469194314\n",
      "Episode 211 finished. 9/20 | 12/20  19.15566037735849\n",
      "Episode 212 finished. 9/20 | 11/20  19.23474178403756\n",
      "Episode 213 finished. 10/20 | 10/20  19.19626168224299\n",
      "Episode 214 finished. 9/20 | 12/20  19.274418604651164\n",
      "Episode 215 finished. 8/20 | 11/20  19.23148148148148\n",
      "Episode 216 finished. 7/20 | 8/20  19.308755760368662\n",
      "Episode 217 finished. 7/20 | 14/20  19.376146788990827\n",
      "Episode 218 finished. 6/20 | 9/20  19.45662100456621\n",
      "Episode 219 finished. 6/20 | 10/20  19.40909090909091\n",
      "Episode 220 finished. 7/20 | 10/20  19.36651583710407\n",
      "Episode 221 finished. 6/20 | 11/20  19.31981981981982\n",
      "Episode 222 finished. 6/20 | 9/20  19.278026905829595\n",
      "Episode 223 finished. 7/20 | 11/20  19.25\n",
      "Episode 224 finished. 8/20 | 14/20  19.20888888888889\n",
      "Episode 225 finished. 9/20 | 9/20  19.172566371681416\n",
      "Episode 226 finished. 9/20 | 10/20  19.13215859030837\n",
      "Episode 227 finished. 9/20 | 17/20  19.13157894736842\n",
      "Episode 228 finished. 9/20 | 5/20  19.087336244541486\n",
      "Episode 229 finished. 9/20 | 12/20  19.056521739130435\n",
      "Episode 230 finished. 9/20 | 11/20  19.017316017316016\n",
      "Episode 231 finished. 9/20 | 17/20  19.103448275862068\n",
      "Episode 232 finished. 9/20 | 12/20  19.06008583690987\n",
      "Episode 233 finished. 8/20 | 15/20  19.145299145299145\n",
      "Episode 234 finished. 8/20 | 14/20  19.217021276595744\n",
      "Episode 235 finished. 8/20 | 11/20  19.300847457627118\n",
      "Episode 236 finished. 9/20 | 12/20  19.27848101265823\n",
      "Episode 237 finished. 9/20 | 8/20  19.361344537815125\n",
      "Episode 238 finished. 10/20 | 15/20  19.334728033472803\n",
      "Episode 239 finished. 11/20 | 16/20  19.3\n",
      "Episode 240 finished. 11/20 | 14/20  19.261410788381742\n",
      "Episode 241 finished. 12/20 | 14/20  19.227272727272727\n",
      "Episode 242 finished. 11/20 | 17/20  19.300411522633745\n",
      "Episode 243 finished. 11/20 | 15/20  19.278688524590162\n",
      "Episode 244 finished. 10/20 | 10/20  19.351020408163265\n",
      "Episode 245 finished. 10/20 | 11/20  19.329268292682926\n",
      "Episode 246 finished. 9/20 | 15/20  19.40080971659919\n",
      "Episode 247 finished. 9/20 | 11/20  19.47983870967742\n",
      "Episode 248 finished. 10/20 | 12/20  19.44176706827309\n",
      "Episode 249 finished. 9/20 | 10/20  19.52\n",
      "Episode 250 finished. 9/20 | 11/20  19.52191235059761\n",
      "Episode 251 finished. 10/20 | 15/20  19.496031746031747\n",
      "Episode 252 finished. 10/20 | 11/20  19.565217391304348\n",
      "Episode 253 finished. 10/20 | 5/20  19.641732283464567\n",
      "Episode 254 finished. 10/20 | 13/20  19.6\n",
      "Episode 255 finished. 10/20 | 11/20  19.67578125\n",
      "Episode 256 finished. 10/20 | 11/20  19.638132295719846\n",
      "Episode 257 finished. 10/20 | 14/20  19.713178294573645\n",
      "Episode 258 finished. 9/20 | 13/20  19.806949806949806\n",
      "Episode 259 finished. 9/20 | 8/20  19.76923076923077\n",
      "Episode 260 finished. 9/20 | 15/20  19.735632183908045\n",
      "Episode 261 finished. 8/20 | 11/20  19.709923664122137\n",
      "Episode 262 finished. 8/20 | 11/20  19.771863117870723\n",
      "Episode 263 finished. 7/20 | 12/20  19.893939393939394\n",
      "Episode 264 finished. 7/20 | 13/20  19.958490566037735\n",
      "Episode 265 finished. 6/20 | 10/20  19.928571428571427\n",
      "Episode 266 finished. 7/20 | 15/20  19.925093632958802\n",
      "Episode 267 finished. 8/20 | 13/20  19.90671641791045\n",
      "Episode 268 finished. 7/20 | 10/20  19.866171003717472\n",
      "Episode 269 finished. 8/20 | 13/20  19.844444444444445\n",
      "Episode 270 finished. 7/20 | 14/20  19.80811808118081\n",
      "Episode 271 finished. 6/20 | 11/20  19.797794117647058\n",
      "Episode 272 finished. 6/20 | 12/20  19.76923076923077\n",
      "Episode 273 finished. 6/20 | 15/20  19.894160583941606\n",
      "Episode 274 finished. 6/20 | 13/20  19.956363636363637\n",
      "Episode 275 finished. 6/20 | 10/20  20.014492753623188\n",
      "Episode 276 finished. 5/20 | 13/20  20.072202166064983\n",
      "Episode 277 finished. 6/20 | 13/20  20.08992805755396\n",
      "Episode 278 finished. 7/20 | 6/20  20.125448028673834\n",
      "Episode 279 finished. 6/20 | 11/20  20.210714285714285\n",
      "Episode 280 finished. 6/20 | 11/20  20.177935943060497\n",
      "Episode 281 finished. 7/20 | 8/20  20.166666666666668\n",
      "Episode 282 finished. 7/20 | 14/20  20.2226148409894\n",
      "Episode 283 finished. 8/20 | 15/20  20.183098591549296\n",
      "Episode 284 finished. 8/20 | 13/20  20.242105263157896\n",
      "Episode 285 finished. 9/20 | 10/20  20.206293706293707\n",
      "Episode 286 finished. 8/20 | 11/20  20.261324041811847\n",
      "Episode 287 finished. 7/20 | 16/20  20.31597222222222\n",
      "Episode 288 finished. 7/20 | 11/20  20.29757785467128\n",
      "Episode 289 finished. 6/20 | 14/20  20.3\n",
      "Episode 290 finished. 7/20 | 12/20  20.29209621993127\n",
      "Episode 291 finished. 7/20 | 11/20  20.301369863013697\n",
      "Episode 292 finished. 8/20 | 16/20  20.266211604095563\n",
      "Episode 293 finished. 8/20 | 12/20  20.231292517006803\n",
      "Episode 294 finished. 9/20 | 12/20  20.2135593220339\n",
      "Episode 295 finished. 9/20 | 8/20  20.179054054054053\n",
      "Episode 296 finished. 10/20 | 11/20  20.144781144781145\n",
      "Episode 297 finished. 9/20 | 10/20  20.197986577181208\n",
      "Episode 298 finished. 9/20 | 12/20  20.163879598662206\n",
      "Episode 299 finished. 9/20 | 14/20  20.216666666666665\n",
      "Episode 300 finished. 9/20 | 12/20  20.182724252491695\n",
      "Episode 301 finished. 8/20 | 10/20  20.1523178807947\n",
      "Episode 302 finished. 9/20 | 7/20  20.174917491749174\n",
      "Episode 303 finished. 8/20 | 12/20  20.14144736842105\n",
      "Episode 304 finished. 8/20 | 9/20  20.111475409836064\n",
      "Episode 305 finished. 7/20 | 15/20  20.163398692810457\n",
      "Episode 306 finished. 7/20 | 14/20  20.127035830618894\n",
      "Episode 307 finished. 7/20 | 9/20  20.0974025974026\n",
      "Episode 308 finished. 8/20 | 11/20  20.097087378640776\n",
      "Episode 309 finished. 9/20 | 9/20  20.06774193548387\n",
      "Episode 310 finished. 8/20 | 14/20  20.192926045016076\n",
      "Episode 311 finished. 8/20 | 10/20  20.16346153846154\n",
      "Episode 312 finished. 8/20 | 9/20  20.15335463258786\n",
      "Episode 313 finished. 8/20 | 11/20  20.11464968152866\n",
      "Episode 314 finished. 7/20 | 10/20  20.165079365079364\n",
      "Episode 315 finished. 7/20 | 11/20  20.161392405063292\n",
      "Episode 316 finished. 6/20 | 11/20  20.123028391167193\n",
      "Episode 317 finished. 7/20 | 7/20  20.10377358490566\n",
      "Episode 318 finished. 6/20 | 14/20  20.153605015673982\n",
      "Episode 319 finished. 7/20 | 8/20  20.15\n",
      "Episode 320 finished. 7/20 | 11/20  20.14018691588785\n",
      "Episode 321 finished. 7/20 | 12/20  20.18633540372671\n",
      "Episode 322 finished. 7/20 | 13/20  20.154798761609907\n",
      "Episode 323 finished. 8/20 | 12/20  20.169753086419753\n",
      "Episode 324 finished. 8/20 | 10/20  20.209230769230768\n",
      "Episode 325 finished. 8/20 | 14/20  20.220858895705522\n",
      "Episode 326 finished. 8/20 | 12/20  20.27217125382263\n",
      "Episode 327 finished. 9/20 | 13/20  20.240853658536587\n",
      "Episode 328 finished. 8/20 | 13/20  20.243161094224924\n",
      "Episode 329 finished. 8/20 | 12/20  20.21212121212121\n",
      "Episode 330 finished. 8/20 | 12/20  20.202416918429\n",
      "Episode 331 finished. 8/20 | 14/20  20.259036144578314\n",
      "Episode 332 finished. 7/20 | 13/20  20.255255255255257\n",
      "Episode 333 finished. 8/20 | 11/20  20.248502994011975\n",
      "Episode 334 finished. 8/20 | 10/20  20.31940298507463\n",
      "Episode 335 finished. 8/20 | 13/20  20.363095238095237\n",
      "Episode 336 finished. 8/20 | 9/20  20.445103857566764\n",
      "Episode 337 finished. 7/20 | 15/20  20.488165680473372\n",
      "Episode 338 finished. 7/20 | 15/20  20.539823008849556\n",
      "Episode 339 finished. 6/20 | 14/20  20.58235294117647\n",
      "Episode 340 finished. 6/20 | 16/20  20.577712609970675\n",
      "Episode 341 finished. 7/20 | 12/20  20.55263157894737\n",
      "Episode 342 finished. 7/20 | 7/20  20.53935860058309\n",
      "Episode 343 finished. 6/20 | 14/20  20.593023255813954\n",
      "Episode 344 finished. 7/20 | 15/20  20.568115942028985\n",
      "Episode 345 finished. 8/20 | 14/20  20.540462427745666\n",
      "Episode 346 finished. 8/20 | 16/20  20.54178674351585\n",
      "Episode 347 finished. 7/20 | 7/20  20.525862068965516\n",
      "Episode 348 finished. 7/20 | 12/20  20.573065902578797\n",
      "Episode 349 finished. 6/20 | 9/20  20.614285714285714\n",
      "Episode 350 finished. 6/20 | 15/20  20.66096866096866\n",
      "Episode 351 finished. 6/20 | 11/20  20.701704545454547\n",
      "Episode 352 finished. 6/20 | 9/20  20.74787535410765\n",
      "Episode 353 finished. 5/20 | 17/20  20.742937853107346\n",
      "Episode 354 finished. 5/20 | 13/20  20.847887323943663\n",
      "Episode 355 finished. 5/20 | 11/20  20.81741573033708\n",
      "Episode 356 finished. 5/20 | 10/20  20.862745098039216\n",
      "Episode 357 finished. 5/20 | 13/20  20.90223463687151\n",
      "Episode 358 finished. 5/20 | 11/20  20.885793871866294\n",
      "Episode 359 finished. 5/20 | 11/20  20.92222222222222\n",
      "Episode 360 finished. 5/20 | 10/20  20.89196675900277\n",
      "Episode 361 finished. 4/20 | 14/20  20.941988950276244\n",
      "Episode 362 finished. 3/20 | 15/20  20.986225895316803\n",
      "Episode 363 finished. 3/20 | 14/20  21.035714285714285\n",
      "Episode 364 finished. 2/20 | 9/20  21.07945205479452\n",
      "Episode 365 finished. 2/20 | 11/20  21.046448087431695\n",
      "Episode 366 finished. 2/20 | 13/20  21.111716621253407\n",
      "Episode 367 finished. 2/20 | 13/20  21.14945652173913\n",
      "Episode 368 finished. 3/20 | 14/20  21.149051490514903\n",
      "Episode 369 finished. 4/20 | 11/20  21.145945945945947\n",
      "Episode 370 finished. 4/20 | 15/20  21.18867924528302\n",
      "Episode 371 finished. 5/20 | 13/20  21.161290322580644\n",
      "Episode 372 finished. 5/20 | 11/20  21.18230563002681\n",
      "Episode 373 finished. 5/20 | 13/20  21.149732620320854\n",
      "Episode 374 finished. 6/20 | 11/20  21.130666666666666\n",
      "Episode 375 finished. 6/20 | 14/20  21.09840425531915\n",
      "Episode 376 finished. 6/20 | 8/20  21.137931034482758\n",
      "Episode 377 finished. 7/20 | 16/20  21.105820105820104\n",
      "Episode 378 finished. 7/20 | 10/20  21.147757255936675\n",
      "Episode 379 finished. 7/20 | 10/20  21.239473684210527\n",
      "Episode 380 finished. 7/20 | 8/20  21.2257217847769\n",
      "Episode 381 finished. 7/20 | 13/20  21.19371727748691\n",
      "Episode 382 finished. 8/20 | 12/20  21.198433420365536\n",
      "Episode 383 finished. 8/20 | 14/20  21.239583333333332\n",
      "Episode 384 finished. 8/20 | 9/20  21.241558441558443\n",
      "Episode 385 finished. 8/20 | 15/20  21.259067357512954\n",
      "Episode 386 finished. 9/20 | 13/20  21.260981912144704\n",
      "Episode 387 finished. 9/20 | 16/20  21.301546391752577\n",
      "Episode 388 finished. 8/20 | 9/20  21.30077120822622\n",
      "Episode 389 finished. 7/20 | 12/20  21.335897435897436\n",
      "Episode 390 finished. 7/20 | 12/20  21.375959079283888\n",
      "Episode 391 finished. 7/20 | 12/20  21.362244897959183\n",
      "Episode 392 finished. 7/20 | 14/20  21.389312977099237\n",
      "Episode 393 finished. 8/20 | 14/20  21.388324873096447\n",
      "Episode 394 finished. 7/20 | 10/20  21.455696202531644\n",
      "Episode 395 finished. 8/20 | 10/20  21.431818181818183\n",
      "Episode 396 finished. 8/20 | 15/20  21.425692695214106\n",
      "Episode 397 finished. 7/20 | 11/20  21.396984924623116\n",
      "Episode 398 finished. 7/20 | 13/20  21.43107769423559\n",
      "Episode 399 finished. 7/20 | 11/20  21.48\n",
      "Episode 400 finished. 6/20 | 15/20  21.518703241895263\n",
      "Episode 401 finished. 7/20 | 11/20  21.492537313432837\n",
      "Episode 402 finished. 6/20 | 13/20  21.4590570719603\n",
      "Episode 403 finished. 6/20 | 12/20  21.43069306930693\n",
      "Episode 404 finished. 6/20 | 13/20  21.469135802469136\n",
      "Episode 405 finished. 5/20 | 10/20  21.440886699507388\n",
      "Episode 406 finished. 4/20 | 9/20  21.496314496314497\n",
      "Episode 407 finished. 4/20 | 13/20  21.46813725490196\n",
      "Episode 408 finished. 4/20 | 11/20  21.52322738386308\n",
      "Episode 409 finished. 4/20 | 11/20  21.495121951219513\n",
      "Episode 410 finished. 4/20 | 12/20  21.549878345498783\n",
      "Episode 411 finished. 3/20 | 9/20  21.59223300970874\n",
      "Episode 412 finished. 3/20 | 14/20  21.61743341404358\n",
      "Episode 413 finished. 2/20 | 11/20  21.659420289855074\n",
      "Episode 414 finished. 2/20 | 13/20  21.71325301204819\n",
      "Episode 415 finished. 1/20 | 14/20  21.754807692307693\n",
      "Episode 416 finished. 1/20 | 14/20  21.808153477218227\n",
      "Episode 417 finished. 1/20 | 10/20  21.779904306220097\n",
      "Episode 418 finished. 1/20 | 14/20  21.816229116945106\n",
      "Episode 419 finished. 1/20 | 15/20  21.857142857142858\n",
      "Episode 420 finished. 2/20 | 15/20  21.855106888361046\n",
      "Episode 421 finished. 2/20 | 11/20  21.83175355450237\n",
      "Episode 422 finished. 2/20 | 10/20  21.85579196217494\n",
      "Episode 423 finished. 2/20 | 10/20  21.891509433962263\n",
      "Episode 424 finished. 2/20 | 11/20  21.901176470588236\n",
      "Episode 425 finished. 2/20 | 14/20  21.87323943661972\n",
      "Episode 426 finished. 3/20 | 11/20  21.85480093676815\n",
      "Episode 427 finished. 3/20 | 12/20  21.827102803738317\n",
      "Episode 428 finished. 3/20 | 10/20  21.82051282051282\n",
      "Episode 429 finished. 3/20 | 11/20  21.793023255813953\n",
      "Episode 430 finished. 4/20 | 14/20  21.765661252900234\n",
      "Episode 431 finished. 4/20 | 9/20  21.738425925925927\n",
      "Episode 432 finished. 5/20 | 13/20  21.727482678983833\n",
      "Episode 433 finished. 5/20 | 13/20  21.70046082949309\n",
      "Episode 434 finished. 5/20 | 13/20  21.671264367816093\n",
      "Episode 435 finished. 5/20 | 10/20  21.66743119266055\n",
      "Episode 436 finished. 6/20 | 8/20  21.643020594965677\n",
      "Episode 437 finished. 7/20 | 12/20  21.67351598173516\n",
      "Episode 438 finished. 7/20 | 12/20  21.660592255125284\n",
      "Episode 439 finished. 7/20 | 10/20  21.69090909090909\n",
      "Episode 440 finished. 6/20 | 13/20  21.72562358276644\n",
      "Episode 441 finished. 5/20 | 12/20  21.764705882352942\n",
      "Episode 442 finished. 6/20 | 14/20  21.776523702031604\n",
      "Episode 443 finished. 6/20 | 14/20  21.756756756756758\n",
      "Episode 444 finished. 6/20 | 12/20  21.808988764044944\n",
      "Episode 445 finished. 6/20 | 10/20  21.847533632286996\n",
      "Episode 446 finished. 5/20 | 13/20  21.89709172259508\n",
      "Episode 447 finished. 5/20 | 14/20  21.935267857142858\n",
      "Episode 448 finished. 5/20 | 13/20  21.971046770601337\n",
      "Episode 449 finished. 5/20 | 13/20  21.95777777777778\n",
      "Episode 450 finished. 5/20 | 11/20  21.933481152993348\n",
      "Episode 451 finished. 6/20 | 14/20  21.913716814159294\n",
      "Episode 452 finished. 5/20 | 10/20  21.91169977924945\n",
      "Episode 453 finished. 5/20 | 11/20  21.944933920704845\n",
      "Episode 454 finished. 5/20 | 17/20  21.993406593406593\n",
      "Episode 455 finished. 6/20 | 11/20  22.00219298245614\n",
      "Episode 456 finished. 5/20 | 14/20  22.024070021881837\n",
      "Episode 457 finished. 5/20 | 11/20  22.050218340611355\n",
      "Episode 458 finished. 5/20 | 14/20  22.021786492374726\n",
      "Episode 459 finished. 5/20 | 15/20  22.054347826086957\n",
      "Episode 460 finished. 5/20 | 14/20  22.036876355748372\n",
      "Episode 461 finished. 5/20 | 13/20  22.015151515151516\n",
      "Episode 462 finished. 5/20 | 12/20  21.995680345572353\n",
      "Episode 463 finished. 5/20 | 11/20  21.969827586206897\n",
      "Episode 464 finished. 5/20 | 10/20  21.976344086021506\n",
      "Episode 465 finished. 5/20 | 13/20  21.950643776824034\n",
      "Episode 466 finished. 5/20 | 10/20  21.957173447537475\n",
      "Episode 467 finished. 5/20 | 11/20  21.94017094017094\n",
      "Episode 468 finished. 5/20 | 13/20  21.93816631130064\n",
      "Episode 469 finished. 5/20 | 9/20  21.908510638297873\n",
      "Episode 470 finished. 4/20 | 13/20  21.955414012738853\n",
      "Episode 471 finished. 4/20 | 14/20  21.9385593220339\n",
      "Episode 472 finished. 4/20 | 11/20  21.98520084566596\n",
      "Episode 473 finished. 4/20 | 12/20  22.018987341772153\n",
      "Episode 474 finished. 4/20 | 12/20  22.00842105263158\n",
      "Episode 475 finished. 3/20 | 14/20  22.039915966386555\n",
      "Episode 476 finished. 3/20 | 12/20  22.046121593291403\n",
      "Episode 477 finished. 3/20 | 11/20  22.023012552301257\n",
      "Episode 478 finished. 3/20 | 9/20  22.02087682672234\n",
      "Episode 479 finished. 4/20 | 8/20  22.0\n",
      "Episode 480 finished. 5/20 | 11/20  22.002079002079004\n",
      "Episode 481 finished. 6/20 | 12/20  21.981327800829874\n",
      "Episode 482 finished. 5/20 | 11/20  21.954451345755693\n",
      "Episode 483 finished. 6/20 | 13/20  21.931818181818183\n",
      "Episode 484 finished. 6/20 | 13/20  21.905154639175258\n",
      "Episode 485 finished. 6/20 | 14/20  21.93621399176955\n",
      "Episode 486 finished. 6/20 | 13/20  21.973305954825463\n",
      "Episode 487 finished. 6/20 | 13/20  21.94877049180328\n",
      "Episode 488 finished. 6/20 | 13/20  21.993865030674847\n",
      "Episode 489 finished. 7/20 | 11/20  21.973469387755102\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m optimize_model(memory)\n\u001b[0;32m     50\u001b[0m number_of_steps\u001b[38;5;241m.\u001b[39mappend(num_steps)\n\u001b[1;32m---> 51\u001b[0m stats \u001b[38;5;241m=\u001b[39m [run_game(target_net) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m)]\n\u001b[0;32m     52\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(win_rate[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m:])\n\u001b[0;32m     53\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m stats)\n",
      "Cell \u001b[1;32mIn[91], line 51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     48\u001b[0m optimize_model(memory)\n\u001b[0;32m     50\u001b[0m number_of_steps\u001b[38;5;241m.\u001b[39mappend(num_steps)\n\u001b[1;32m---> 51\u001b[0m stats \u001b[38;5;241m=\u001b[39m [\u001b[43mrun_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_net\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m)]\n\u001b[0;32m     52\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(win_rate[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m:])\n\u001b[0;32m     53\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m stats)\n",
      "Cell \u001b[1;32mIn[89], line 9\u001b[0m, in \u001b[0;36mrun_game\u001b[1;34m(net)\u001b[0m\n\u001b[0;32m      7\u001b[0m \t\u001b[38;5;28;01mwhile\u001b[39;00m board\u001b[38;5;241m.\u001b[39mgame_state \u001b[38;5;241m==\u001b[39m GameState\u001b[38;5;241m.\u001b[39mNOT_OVER \u001b[38;5;129;01mand\u001b[39;00m board\u001b[38;5;241m.\u001b[39mturn_sign \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      8\u001b[0m \t\t\u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 9\u001b[0m \t\t\tstate_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[43mq_s\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard\u001b[49m\u001b[43m)\u001b[49m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     10\u001b[0m \t\t\tboard\u001b[38;5;241m.\u001b[39mmake_move(\u001b[38;5;241m*\u001b[39mstate_values\u001b[38;5;241m.\u001b[39maction)\n\u001b[0;32m     12\u001b[0m pieces \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[86], line 17\u001b[0m, in \u001b[0;36mq_s\u001b[1;34m(dqn, current_state)\u001b[0m\n\u001b[0;32m     15\u001b[0m \t\tnext_state \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(current_state)\n\u001b[0;32m     16\u001b[0m \t\timmediate_reward \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([next_state\u001b[38;5;241m.\u001b[39mmake_move(s, e) \u001b[38;5;241m*\u001b[39m next_state\u001b[38;5;241m.\u001b[39mturn_sign], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 17\u001b[0m \t\tvalue \u001b[38;5;241m=\u001b[39m \u001b[43mdqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m GAMMA \u001b[38;5;241m+\u001b[39m immediate_reward\n\u001b[0;32m     18\u001b[0m \t\tret\u001b[38;5;241m.\u001b[39mappend(Action((s, e), value))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\user\\docs\\TUM\\ReinforcementLearning\\repos\\romaAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\user\\docs\\TUM\\ReinforcementLearning\\repos\\romaAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[84], line 35\u001b[0m, in \u001b[0;36mDQN.forward\u001b[1;34m(self, board)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, board: Board) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 35\u001b[0m \tstate \u001b[38;5;241m=\u001b[39m \u001b[43mboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     37\u001b[0m \t\tstate \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(layer(state))\n",
      "File \u001b[1;32mc:\\user\\docs\\TUM\\ReinforcementLearning\\repos\\romaAI\\algo\\board.py:415\u001b[0m, in \u001b[0;36mBoard.to_tensor\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    413\u001b[0m board \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__board\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flipped:\n\u001b[1;32m--> 415\u001b[0m \tboard \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mboard\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    417\u001b[0m pos \u001b[38;5;241m=\u001b[39m _c(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m18\u001b[39m):\n\u001b[0;32m    419\u001b[0m \t\u001b[38;5;66;03m#       possition coding                   piece coding\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "\tnum_episodes = 600\n",
    "else:\n",
    "\tnum_episodes = 50\n",
    "\t\n",
    "memory: list[TransitionRecord] = []\n",
    "\n",
    "win_rate = []\n",
    "number_of_steps = []\n",
    "\n",
    "enemy = RandomPlayer(random.randint(0, 1000))\n",
    "q_enemy = QLearning(\"dqn80.pth\")\n",
    "random_enemy = RandomPlayer(random.randint(0, 1000))\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "\tenemy = random.choice([q_enemy, random_enemy])\n",
    "\t# enemy = random_enemy\n",
    "\tcur_state = Board()\n",
    "\t\n",
    "\tif i_episode % 2 == 0:\n",
    "\t\tour_sign = -1\n",
    "\t\tcur_state.make_move(*enemy.decide_move(cur_state))\n",
    "\telse:\n",
    "\t\tour_sign = 1\n",
    "\n",
    "\tnum_steps = 0\n",
    "\twhile True:\n",
    "\t\tnum_steps += 1\n",
    "\t\taction = select_action(cur_state)\n",
    "\t\tnew_state, immediate_reward = make_environment_step(cur_state, action.action, enemy, num_steps)\n",
    "\n",
    "\t\tmemory.append(TransitionRecord(cur_state, new_state, torch.tensor([immediate_reward], device=device)))\n",
    "\t\tcur_state = new_state\n",
    "\t\t\n",
    "\t\t# Soft update of the target network's weights\n",
    "\t\t# θ′ ← τ θ + (1 −τ )θ′\n",
    "\t\ttarget_net_state_dict = target_net.state_dict()\n",
    "\t\tpolicy_net_state_dict = policy_net.state_dict()\n",
    "\t\tfor key in policy_net_state_dict:\n",
    "\t\t\ttarget_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "\t\ttarget_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "\t\tif cur_state.game_state != GameState.NOT_OVER:\n",
    "\t\t\twin_rate.append(cur_state.game_state == GameState(our_sign))\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# Perform one step of the optimization (on the policy network)\n",
    "\toptimize_model(memory)\n",
    "\n",
    "\tnumber_of_steps.append(num_steps)\n",
    "\tstats = [run_game(target_net) for _ in range(20)]\n",
    "\ta = sum(win_rate[-20:])\n",
    "\tb = sum(x > 0 for x in stats)\n",
    "\n",
    "\tif a * b > max_score:\n",
    "\t\tmax_score = a * b\n",
    "\t\tbackup = copy.deepcopy(target_net)\n",
    "\n",
    "\tprint(f\"Episode {i_episode} finished. {a}/{20} | {b}/20  {sum(number_of_steps)/len(number_of_steps)}\")\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.384928716904277"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(win_rate) / len(win_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(win_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(win_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(225)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(618), 1000)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHOlJREFUeJzt3QuQXvP9P/BPkk3SinWXRMK4h0qCiWvUrdJMg2ioQdG6VdH4MZRBhnGrNsUk0UnQShRFS0dQl5AIqQoRbRRxiWvcQi6EJHVJIjn/+R7/3WaJktj1fPfZ12vmO2fP5TnP9+yzz+57v5fztIqIIgAAMtK60hUAAPgsAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOzXRTHXp0iUWLFhQ6WoAACugtrY23nrrreoMKCmczJgxo9LVAABWQteuXb80pDTLgFLXcpIuUCsKADSf1pPUwPBV/nY3y4BSJ12ggAIA1ccgWQAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKANC8A8pZZ50Vjz32WMyfPz9mzZoVt912W3Tr1q3BMRMmTIiiKBqUK6+8ssExG2ywQdx1113xwQcflOe55JJLok2bNo1zRQBAs7dCn8Wzxx57xOWXXx7//Oc/o6amJn7zm9/EuHHjYquttooPP/yw/rirrroqzj333Pr1Zfe1bt067r777pg5c2bssssusd5668Wf/vSnWLx4cZx99tmNdV0AQDNXrGxZZ511imS33Xar3zZhwoRi2LBhX/iYfv36FZ988knRsWPH+m3HH3988f777xdt27b9Ss9bW1tbPm9afp36K4qiKIoS31hZkb/fX2sMyuqrr14u586d22D74YcfHnPmzImpU6eWrSzf/va36/f17t273D579uz6bWPHji3P1b179+U+T7t27cqPaF62AADVa4W6eJbVqlWruOyyy2LixInxzDPP1G//85//HK+99lq89dZbsfXWW8fFF18cW2yxRRx44IHl/s6dO5fjTpZVt572Lc+gQYPi/PPPX9mqAjS5IVMnRXNzWs/ela4CNH5ASWNRevToEbvuumuD7SNHjqz/+umnn4633347Hnjggdhkk03ilVdeWannGjx4cAwdOrR+PbWgzJgxY2WrDgBkbqW6eIYPHx79+/eP733ve18aFCZPnlwuN9tss3KZBsd26tSpwTF162nf8ixatCgWLFjQoAAA1av1yoSTAw44IPbaa6949dVXv/T4bbfdtlymlpRk0qRJ0bNnz1h33XXrj+nbt2/Mmzcvnn322RWtDgDQ0rt4UrfOYYcdFgMGDChbMepaPlK4+Pjjj8tunLR/zJgx8e6775ZjUIYNGxYPPvhgOTA2SdOSUxC5/vrr44wzzijHnVx00UXluVNLCQDACrWgDBw4MNZYY40ycKTumLpyyCGHlPtTwPj+979fhpBp06bFkCFDYvTo0bHffvvVn2Pp0qVl99CSJUvK1pQbbrihvA/KsvdNAQBatpoVnbnzv7z55pux5557ful5Xn/99dh3331X5KkBgBbEZ/EAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAoHkHlLPOOisee+yxmD9/fsyaNStuu+226NatW4Nj2rdvHyNGjIh33nknFixYELfcckt07NixwTEbbLBB3HXXXfHBBx+U57nkkkuiTZs2jXNFAEDLCih77LFHXH755bHzzjtH3759o23btjFu3LhYZZVV6o8ZNmxY7LfffnHQQQeVx3fp0iVuvfXW/z5h69Zx9913R7t27WKXXXaJI488Mo466qi48MILG/fKAIBmq1VEFCv74HXWWSfmzJkTu+++ezz00EOx2mqrleuHHXZYjB49ujxmiy22iGnTppWhZvLkydGvX7+y9SQFl9mzZ5fHHH/88XHxxRfHuuuuG4sXL/7S562trS1bcdLzpVYagEobMnVSNDen9exd6SrQwtSuwN/vrzUGZfXVVy+Xc+fOLZfbbbdd2TIyfvz4+mOef/75eO2116J370/fCGk5derU+nCSjB07tjxX9+7dl/s86ZzpopYtAED1WumA0qpVq7jsssti4sSJ8cwzz5TbOnfuHAsXLox58+Y1ODaNM0n76o5J65/dX7dveQYNGlQmrroyY8aMla02AFDNASWNRenRo0f8+Mc/jqY2ePDgsjmornTt2rXJnxMAqJyalXnQ8OHDo3///uXYk2VbM2bOnFnO4kndNcu2onTq1KncV3fMjjvu2OB8aX/dvuVZtGhRWQCAlqH1yoSTAw44IPbaa6949dVXG+ybMmVKGST69OlTvy1NQ95www1j0qRPB5ClZc+ePcsBsXXSjKAUaJ599tmvdzUAQMtrQUndOmmGzoABA8rRt3UtHylcfPzxx+X4kKuvvjqGDh1aDpxN6ynQPPLII+UMniRNS05B5Prrr48zzjijHHdy0UUXlefWSgIArHBAGThwYLl88MEHG2xP9zG57rrryq9PPfXUWLp0aTnNOHX3pBk6dY9L0r7UPXTllVeWrSnpZm3pseeee65XBAD4+vdBqRT3QQFy4z4okNF9UAAAmoKAAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABAJp/QNltt93ijjvuiBkzZkRRFDFgwIAG+6+55ppy+7LlnnvuaXDMmmuuGTfccEPMmzcv3nvvvRg1alR06NDh618NANAyA0oKEk8++WSceOKJX3hMCiSdO3euL4ceemiD/TfeeGN07949+vbtG/3794/dd989rrrqqpW7AgCg6tSs6APuvffesvwvCxcujFmzZi1335Zbbhl77713bL/99jFlypRy20knnRRjxoyJ008/Pd5+++0VrRIAUGWaZAzKnnvuWQaUadOmxRVXXBFrrbVW/b7evXuX3Tp14SQZP358LF26NHbaaaflnq9du3ZRW1vboAAA1avRA0pqXTniiCOiT58+ceaZZ8Yee+xRdvm0bv3pU6Uun9mzZzd4zJIlS2Lu3LnlvuUZNGhQzJ8/v76k8S8AQPVa4S6eL3PzzTfXf/3000/HU089Fa+88krZqvLAAw+s1DkHDx4cQ4cOrV9PLShCCgBUryafZjx9+vSYM2dObLbZZuX6zJkzo2PHjg2OadOmTdkNlPYtz6JFi2LBggUNCgBQvRq9BeWzunbtGmuvvXb94NdJkyaV04x79eoVjz/+eLltr732KruAJk+e3NTVISNDpk6K5ua0nr0rXQWAFqFmZaYZ17WGJBtvvHFss8025RiSVM4777wYPXp02Rqy6aabxiWXXBIvvfRSjB07tjw+DZxNY1JGjhwZJ5xwQrRt2zZGjBgRN910kxk8AMDKdfGk6cFPPPFEWZJhw4aVX1944YXlYNett966vJHbCy+8EFdffXU5Wyfd3C1109Q5/PDDy6By//33l9OLJ06cGMcdd9yKVgUAqFIr3ILy4IMPRqtWrb5wf79+/b70HGmacQopAADL47N4AIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyE5NpSsAAF/VkKmTork5rWfvSlehWdKCAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALJTU+kKAHzWkKmTKl0FoMK0oAAA2dGCAtBCaakiZ1pQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAAzT+g7LbbbnHHHXfEjBkzoiiKGDBgwOeOueCCC+Ktt96KDz/8MO67777YbLPNGuxfc80144Ybboh58+bFe++9F6NGjYoOHTp8vSsBAFpuQElB4sknn4wTTzxxufvPOOOMOPnkk+OEE06InXbaKT744IMYO3ZstG/fvv6YG2+8Mbp37x59+/aN/v37x+677x5XXXXV17sSAKBq1KzoA+69996yfJFTTjklLrroorKVJTniiCNi1qxZsf/++8fNN98cW265Zey9996x/fbbx5QpU8pjTjrppBgzZkycfvrp8fbbb3+d6wEAqkCjjkHZeOONY7311ovx48fXb5s/f35Mnjw5evfuXa6nZerWqQsnSTp+6dKlZYvL8rRr1y5qa2sbFACgeq1wC8r/0rlz53KZWkyWldbr9qXl7NmzG+xfsmRJzJ07t/6Yzxo0aFCcf/75jVlVWClDpk6K5ua0np/+cwDQnDSLWTyDBw+O1VZbrb507dq10lUCAJpLQJk5c2a57NSpU4Ptab1uX1p27Nixwf42bdrEWmutVX/MZy1atCgWLFjQoAAA1atRA8r06dPLQa59+vSp35bGi6SxJZMmfdo0npZpmnGvXr3qj9lrr72idevW5VgVAICalZlmvOx9TdLA2G222aYcQ/LGG2/EZZddFuecc068+OKLZWD51a9+Vd4T5fbbby+PnzZtWtxzzz0xcuTIcipy27ZtY8SIEXHTTTeZwQMArFxASdOD//73v9evDxs2rFxee+21cfTRR8cll1xShph0X5M11lgjJk6cGP369YuFCxfWP+bwww8vQ8n9999fzt4ZPXp0ee8UAICkVUQUze1bkbqN0vTlNGDWeJTmqznOiGmOmuMsHj8bVJPm+B7M4e93s5jFAwC0LAIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDsCCgAQHYEFAAgOwIKAJAdAQUAyI6AAgBkR0ABALIjoAAA2RFQAIDs1FS6AkDTGjJ1UqWrALDCtKAAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAoPoDynnnnRdFUTQozz33XP3+9u3bx4gRI+Kdd96JBQsWxC233BIdO3Zs7GoAAM1Yk7SgPP3009G5c+f6suuuu9bvGzZsWOy3335x0EEHxR577BFdunSJW2+9tSmqAQA0UzVNcdJPPvkkZs2a9bntq622WvzsZz+Lww47LCZMmFBuO/roo2PatGmx0047xeTJk5uiOgBAM9MkLSibb755zJgxI15++eW44YYbYoMNNii3b7fddtGuXbsYP358/bHPP/98vPbaa9G7d+8vPF96TG1tbYMCAFSvRg8oqRXkqKOOin79+sUvfvGL2HjjjeOhhx6KVVddtezuWbhwYcybN6/BY1JrS9r3RQYNGhTz58+vLyn8AADVq9G7eO699976r6dOnVoGltRCcvDBB8dHH320UuccPHhwDB06tH49taAIKQBQvZp8mnFqLXnhhRdis802i5kzZ5azeFZfffUGx3Tq1Knc90UWLVpUzvhZtgAA1avJA0qHDh1i0003jbfffjumTJlSho0+ffrU7+/WrVtsuOGGMWnSpKauCgDQUrt4Lr300rjzzjvLbp00hfiCCy6IJUuWxF/+8pdy/MjVV19ddtfMnTu3XB8+fHg88sgjZvB8TUOmCngAVI9GDyjrr79+GUbWXnvtmDNnTkycODF23nnn8sZsyamnnhpLly6N0aNHl909Y8eOjYEDBzZ2NQCAZqxVRBTRzKRBsqn1Jd1XxXiUT2lBAcjTaT2/+DYaLU3tCvz99lk8AEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZEdAAQCyI6AAANkRUACA7AgoAEB2BBQAIDsCCgCQHQEFAMiOgAIAZKem0hXI0ZCpkypdBQBo0bSgAADZEVAAgOwIKABAdgQUACA7AgoAkB0BBQDIjoACAGRHQAEAsiOgAADZEVAAgOwIKABAdgQUACA7AgoAkB0BBQDIjoACAGRHQAEAsiOgAADZqal0BQCgmg2ZOimao9N69q7o82tBAQCyI6AAANkRUACA7FQ0oAwcODCmT58eH330UTz66KOxww47VLI6AEBLDygHH3xwDB06NC644ILo1atXPPnkkzF27NhYd911K1UlAKClB5Rf/vKXMXLkyLj22mvjueeeixNOOCE+/PDDOOaYYypVJQCgJU8zbtu2bWy33XYxePDg+m1FUcT48eOjd+/PT2tq165dtG/fvn69tra2wbKxtWvdpknOCwDNRW0T/I1dkXNWJKCss846UVNTE7NmzWqwPa1vueWWnzt+0KBBcf75539u+4wZM5q0ngDQUv3f/PlNdu4UVBYsWND8b9SWWlrSeJVlrbXWWjF37tyoFunFSoGra9euX/qiVQPXW91cb3VzvdWvtgmvOZ37rbfe+tLjKhJQ3nnnnfjkk0+iU6dODban9ZkzZ37u+EWLFpVlWdX6Q5Kuq1qvbXlcb3VzvdXN9Va/BU1wzV/1fBUZJLt48eKYMmVK9OnTp35bq1atyvVJk5rnLYEBgMZTsS6e1GVz3XXXxb/+9a947LHH4pRTTokOHTrENddcU6kqAQAtPaD89a9/Le95cuGFF0bnzp3jiSeeiH79+sXs2bOjJVq4cGE5EDgtWwLXW91cb3VzvdVvYQbX3CrN8K3YswMALIfP4gEAsiOgAADZEVAAgOwIKABAdgSUTO2zzz7x6KOPlh+gmO6Ye9ttt0W1S5+59O9//7v8XKZtttkmqtGGG24Yo0aNildeeaV8bV966aVypHz6fKpqMnDgwJg+fXp89NFH5c/xDjvsENXorLPOKm+TMH/+/PKjOtL7tFu3btFSnHnmmeX7ddiwYVGtunTpEtdff315g9H0nn3qqafKz5KrRq1bty5n1i77++mcc86paJ3SLB4lo/KjH/2oePfdd4vjjz++2HzzzYvvfOc7xUEHHVTxejV1ueyyy4q77767SLbZZpuK16cpyg9+8IPij3/8Y9G3b99i4403Lvbbb79i5syZxaWXXlrxujVWOfjgg4uPP/64OOqoo8qf3T/84Q/F3Llzi3XXXbfidWvscs899xRHHnlksdVWWxVbb711cddddxWvvvpqscoqq1S8bk1dtt9+++KVV14pnnjiiWLYsGEVr09TlDXWWKOYPn16+Z7dYYcdio022qh8726yySYVr1s0QRk0aFAxZ86cYp999ik23HDD4sADDyzmz59fnHTSSZWqU+W/Kcp/S5s2bYo33nijOOaYYypel2+y9OvXr3j22WfLP2jVHFCWV04//fTi5Zdfrng9Gqs8+uijxfDhw+vXW7VqVbz55pvFmWeeWfG6NXVZZ511yp/f3XbbreJ1acrSoUOH4vnnny/69OlTTJgwoWoDyuDBg4t//OMfFa9HfEPlzjvvLEaNGtVg2y233FJcf/31FamPLp7M9OrVK9Zff/1YunRpPP744+UHKo0ZMya6d+8e1apjx44xcuTI+OlPf1o2K7Y0q6++etV88GXqqkrN3+PHj6/flroA0nrv3r2jJbyWSbW8nl/k8ssvj7vvvjvuv//+qGY//OEPy7udpxuLpi689Dv52GOPjWr1yCOPlB85s/nmm5frW2+9dey6665xzz33VKxOFU9tyn/LIYccUv4HlpqJU1dPr169ihtvvLFsdltzzTUrXr+mKGPGjCnOPvvs8uvUrNiSWlA23XTT4v333y+OPfbYitelMcp6661Xvn4777xzg+0XX3xx2bJS6fo1ZUktRek/0IceeqjidWnq31FPPfVU0b59+3K9mltQPvroo7L8+te/Lrbddtvi5z//efHhhx8WRxxxRMXrFk30M5xajZYsWVIsWrSoXJ511lmVrFPlvyktoaQX/ctsscUWxaGHHlp+nd4IdY9t165dMXv27OK4446ruutNfZvpF3rr1q2bdUD5qte77GO6dOlSvPjii8XIkSMrXv/GKi05oFxxxRXleIWuXbtWvC5NVdZff/1yzFTPnj3rt1VzQFm4cGHx8MMPN9j2u9/9rnjkkUcqXrdoovD5+uuvl8sePXoUP/nJT4p33nmnkoGs8t+UllBS33T6A/W/Stu2bYs999yz/AX/3e9+t8Hj0y/3iy66qOqu97bbbis++eSTYvHixfUlSctrr7226q532T/kqQ//uuuuK/9rqXT9G6uka0yv3YABAxpsT6/l7bffXvH6NVVJY27SL/Y0iLLSdWnKkl7Xuvfnsu/X9J92+rruH41qKakl+7P/QJxwwgnlmKpK1y2aoKSf4YEDBzbYllq3n3vuuYrUp2IfFtjSpClqqXyZKVOmxMcffxxbbLFFPPzww+W2mpqa2GijjeK1116Larvek08+ucE0tjSlb9y4cXHIIYfE5MmTo9qut+4aJ0yYUL7WRx99dDlGo1osXry4vK7Uj/23v/2t3NaqVatyfcSIEVGNhg8fHgcccEDsueee8eqrr0Y1S2NOevTo0WBb+gT6adOmxcUXX1yOnasm6Xdw+l28rDSNvDn9Ll4Rq6yyyudewyVLlpTTjyul4qlNaVhSc2mayZOms3Xr1q1M8KlZNU15q3Tdmro01y6er1pSt84LL7xQ3HfffeXXnTp1qi+VrltjTjNO/fapWXjLLbcsfv/735fTjDt27FjxujV2ufzyy4v33nuv2H333Ru8lt/61rcqXrdvqlRzF0+aSp3GYqTpt2m8WOqC/89//lMcdthhFa9bNEG55ppryr89ddOM999//3J4wW9/+9tK1any3xSlYampqSnvi5FCybx584px48aV91modL2+iVLtASXdM+OLVLpujVlOPPHEsnk83Q8ldU/uuOOOFa9TU5Qvkl7nStftmyrVHFBS2XfffctBwSl0p1shVMuA9lhOWXXVVcvXMr1302Dgl156qfjVr37VoHv6myyt/v8XAADZcB8UACA7AgoAkB0BBQDIjoACAGRHQAEAsiOgAADZEVAAgOwIKABAdgQUACA7AgoAkB0BBQDIjoACAERu/h+vj73qd7IDYAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = [run_game(target_net) for _ in range(1000)]\n",
    "\n",
    "plt.hist(stats)\n",
    "sum(x > 0 for x in stats), len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(585), 1000)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = [run_game(policy_net) for _ in range(1000)]\n",
    "\n",
    "plt.hist(stats)\n",
    "sum(x > 0 for x in stats), len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(587), 1000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert backup\n",
    "stats = [run_game(backup) for _ in range(1000)]\n",
    "\n",
    "plt.hist(stats)\n",
    "sum(x > 0 for x in stats), len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(policy_net.state_dict(), \"~dqn83 90 50 20 1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_net.load_state_dict(torch.load(\"dqn.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
