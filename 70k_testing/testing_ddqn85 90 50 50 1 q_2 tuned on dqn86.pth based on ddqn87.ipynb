{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState, MoveResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_SIGN = -1\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t50,\n",
    "\t\t\t50,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayer = nn.Linear(prev_size, cur_size)\n",
    "\t\t\t# nn.init.kaiming_uniform(layer.weight, nonlinearity='relu')\n",
    "\t\t\tlayers.append(layer)\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(\n",
    "\t\t\tdevice,\n",
    "\t\t\tboard.turn_sign != DEPLOYMENT_SIGN\n",
    "\t\t)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_result_to_reward(move_result: MoveResult) -> float:\n",
    "    return move_result.captured + move_result.promoted * 2\n",
    "\n",
    "def state_to_reward(state: Board) -> float:\n",
    "\treturn -2 * (state.moves_since_last_capture > 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([\n",
    "\t\t\t\tmove_result_to_reward(next_state.make_move(s, e)) + \n",
    "\t\t\t\tstate_to_reward(next_state)\n",
    "\t\t\t], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.05001 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.006 # update rate\n",
    "LR = 1e-4 # AdamW learning rate\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(dqn: DQN, board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(dqn, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer, current_step: int) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\n",
    "\treward = move_result_to_reward(state.make_move(*action)) + state_to_reward(state)\n",
    "\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\treward -= move_result_to_reward(state.make_move(*enemy.decide_move(state)))\n",
    "\n",
    "\t# if current_step > 10 and not we_captured:\n",
    "\t# \treward -= 2\n",
    "\t\t\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_94944\\3284383400.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_net.load_state_dict(torch.load(\"./testing/ddqn85 90 50 50 1 q_2 tuned on dqn86.pth based on ddqn87.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1437.,  1317.,  1897.,  4087.,     0.,  2334., 25899., 20742.,\n",
       "        10809.,  1478.]),\n",
       " array([-6. , -4.7, -3.4, -2.1, -0.8,  0.5,  1.8,  3.1,  4.4,  5.7,  7. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "test_net = DQN()\n",
    "test_net.load_state_dict(torch.load(\"./testing/ddqn85 90 50 50 1 q_2 tuned on dqn86.pth based on ddqn87.pth\"))\n",
    "\n",
    "# enemy = QLearning(\"90_52_1_9130.pth\", [90, 52, 1])\n",
    "\n",
    "for i in range(70000):\n",
    "\tenemy = RandomPlayer(i)\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(test_net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\t# while board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t# \tboard.make_move(*enemy.decide_move(board))\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\t\n",
    "\tresult = (1 if board.game_state == GameState(-1) else -1) * abs(pieces)\n",
    "\t\n",
    "\tstats.append(result)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8751714285714286"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x in stats if x > 0) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./testing/ddqn85 90 50 50 1 q_2 tuned on dqn86.pth based on ddqn87_stats.pth\", \"wb\") as f:\n",
    "\tpickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.770542857142857"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
