{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t52,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayers.append(nn.Linear(prev_size, cur_size))\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(device)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\twe_captured = state.make_move(*action) * cur_sign\n",
    "\treward = 0\n",
    "\n",
    "\tfor pos, piece in state:\n",
    "\t\tif (cur_sign == 1 and piece == 2 and pos[1] > 3) or \\\n",
    "\t\t\t(cur_sign == -1 and piece == -2 and pos[1] < 2):\n",
    "\t\t\treward -= 1\n",
    "\n",
    "\tenemy_captured = 0\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\tenemy_captured += state.make_move(*enemy.decide_move(state)) * cur_sign * (-1)\n",
    "\t\t\n",
    "\treward += we_captured - enemy_captured\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([next_state.make_move(s, e) * next_state.turn_sign], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_359512\\3620171565.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy_net.load_state_dict(torch.load(\"90_52_1_89  miracle2 percentdqn.pth\"))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.9 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.009 # update rate\n",
    "LR = 1e-2 # AdamW learning rate\n",
    "\n",
    "policy_net = DQN().to(device) # to be updated often\n",
    "target_net = DQN().to(device) # to be updated with TAU\n",
    "policy_net.load_state_dict(torch.load(\"90_52_1_89  miracle2 percentdqn.pth\"))\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(policy_net, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.800e+01, 4.240e+02, 8.310e+02, 3.000e+00, 0.000e+00, 2.077e+03,\n",
       "        1.259e+03, 3.309e+03, 1.252e+03, 8.270e+02]),\n",
       " array([-5. , -3.8, -2.6, -1.4, -0.2,  1. ,  2.2,  3.4,  4.6,  5.8,  7. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "enemy = RandomPlayer(random.randint(0, 20000))\n",
    "# enemy = QLearning(\"90_52_1_9130.pth\", [90, 52, 1])\n",
    "\n",
    "for i in range(10000):\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(target_net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\t# while board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t# \tboard.make_move(*enemy.decide_move(board))\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\t\n",
    "\tresult = (1 if board.game_state == GameState(-1) else -1) * abs(pieces)\n",
    "\t\n",
    "\tstats.append(result)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8724"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x in stats if x > 0) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"dqn_y89_90_52_1.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.8955)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
