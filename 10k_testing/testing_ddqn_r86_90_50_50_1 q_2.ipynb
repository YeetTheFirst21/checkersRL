{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState, MoveResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_SIGN = -1\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t50,\n",
    "\t\t\t50,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayer = nn.Linear(prev_size, cur_size)\n",
    "\t\t\t# nn.init.kaiming_uniform(layer.weight, nonlinearity='relu')\n",
    "\t\t\tlayers.append(layer)\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(\n",
    "\t\t\tdevice,\n",
    "\t\t\tboard.turn_sign != DEPLOYMENT_SIGN\n",
    "\t\t)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_result_to_reward(move_result: MoveResult) -> float:\n",
    "    return move_result.captured + move_result.promoted * 2\n",
    "\n",
    "def state_to_reward(state: Board) -> float:\n",
    "\treturn -2 * (state.moves_since_last_capture > 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([\n",
    "\t\t\t\tmove_result_to_reward(next_state.make_move(s, e)) + \n",
    "\t\t\t\tstate_to_reward(next_state)\n",
    "\t\t\t], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.05001 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.006 # update rate\n",
    "LR = 1e-4 # AdamW learning rate\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(dqn: DQN, board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(dqn, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer, current_step: int) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\n",
    "\treward = move_result_to_reward(state.make_move(*action)) + state_to_reward(state)\n",
    "\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\treward -= move_result_to_reward(state.make_move(*enemy.decide_move(state)))\n",
    "\n",
    "\t# if current_step > 10 and not we_captured:\n",
    "\t# \treward -= 2\n",
    "\t\t\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_84300\\3305525678.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_net.load_state_dict(torch.load(\"ddqn86 90 50 50 1 q_2 tuned on ddqn86.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 2071.,  2231.,  2699.,  1765.,     0.,  1530., 25582., 20794.,\n",
       "        11487.,  1841.]),\n",
       " array([-6. , -4.7, -3.4, -2.1, -0.8,  0.5,  1.8,  3.1,  4.4,  5.7,  7. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "test_net = DQN()\n",
    "test_net.load_state_dict(torch.load(\"ddqn86 90 50 50 1 q_2 tuned on ddqn86.pth\"))\n",
    "\n",
    "# enemy = QLearning(\"90_52_1_9130.pth\", [90, 52, 1])\n",
    "\n",
    "for i in range(70000):\n",
    "\tenemy = RandomPlayer(i)\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(test_net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\t# while board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t# \tboard.make_move(*enemy.decide_move(board))\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\t\n",
    "\tresult = (1 if board.game_state == GameState(-1) else -1) * abs(pieces)\n",
    "\t\n",
    "\tstats.append(result)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8747714285714285"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x in stats if x > 0) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./testing/ddqn86 90 50 50 1 q_2 tuned on ddqn86_stats.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7388285714285714"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
