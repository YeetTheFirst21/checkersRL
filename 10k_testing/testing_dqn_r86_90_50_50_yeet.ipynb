{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t50,\n",
    "\t\t\t50,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayers.append(nn.Linear(prev_size, cur_size))\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(device)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\twe_captured = state.make_move(*action) * cur_sign\n",
    "\treward = 0\n",
    "\n",
    "\tfor pos, piece in state:\n",
    "\t\tif (cur_sign == 1 and piece == 2 and pos[1] > 3) or \\\n",
    "\t\t\t(cur_sign == -1 and piece == -2 and pos[1] < 2):\n",
    "\t\t\treward -= 1\n",
    "\n",
    "\tenemy_captured = 0\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\tenemy_captured += state.make_move(*enemy.decide_move(state)) * cur_sign * (-1)\n",
    "\t\t\n",
    "\treward += we_captured - enemy_captured\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([next_state.make_move(s, e) * next_state.turn_sign], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_358248\\703064209.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy_net.load_state_dict(torch.load(\"~dqn86 90 50 50 1 tuned on Yeet.pth\"))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.9 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.009 # update rate\n",
    "LR = 1e-2 # AdamW learning rate\n",
    "\n",
    "policy_net = DQN().to(device) # to be updated often\n",
    "target_net = DQN().to(device) # to be updated with TAU\n",
    "policy_net.load_state_dict(torch.load(\"~dqn86 90 50 50 1 tuned on Yeet.pth\"))\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(policy_net, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.072e+03, 5.350e+02, 6.460e+02, 1.000e+00, 0.000e+00, 5.350e+02,\n",
       "        5.390e+02, 1.724e+03, 2.045e+03, 2.903e+03]),\n",
       " array([-5. , -3.9, -2.8, -1.7, -0.6,  0.5,  1.6,  2.7,  3.8,  4.9,  6. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "enemy = RandomPlayer(random.randint(0, 20000))\n",
    "# enemy = QLearning(\"90_52_1_9130.pth\", [90, 52, 1])\n",
    "\n",
    "for i in range(10000):\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(target_net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\t# while board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t# \tboard.make_move(*enemy.decide_move(board))\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\t\n",
    "\tresult = (1 if board.game_state == GameState(-1) else -1) * abs(pieces)\n",
    "\t\n",
    "\tstats.append(result)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7746"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x in stats if x > 0) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"dqn86_90_50_50_1_yeet_stats.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.2298)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
