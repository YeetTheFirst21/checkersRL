{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t50,\n",
    "\t\t\t50,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayers.append(nn.Linear(prev_size, cur_size))\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(device)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\twe_captured = state.make_move(*action) * cur_sign\n",
    "\treward = 0\n",
    "\n",
    "\tfor pos, piece in state:\n",
    "\t\tif (cur_sign == 1 and piece == 2 and pos[1] > 3) or \\\n",
    "\t\t\t(cur_sign == -1 and piece == -2 and pos[1] < 2):\n",
    "\t\t\treward -= 1\n",
    "\n",
    "\tenemy_captured = 0\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\tenemy_captured += state.make_move(*enemy.decide_move(state)) * cur_sign * (-1)\n",
    "\t\t\n",
    "\treward += we_captured - enemy_captured\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([next_state.make_move(s, e) * next_state.turn_sign], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_356148\\4050171733.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy_net.load_state_dict(torch.load(\"dqn80.pth\"))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.9 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.009 # update rate\n",
    "LR = 1e-2 # AdamW learning rate\n",
    "\n",
    "policy_net = DQN().to(device) # to be updated often\n",
    "target_net = DQN().to(device) # to be updated with TAU\n",
    "policy_net.load_state_dict(torch.load(\"dqn80.pth\"))\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(policy_net, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 175.,  290.,  759.,  466.,  232.,  580., 1340., 4767., 1159.,\n",
       "         232.]),\n",
       " array([-7. , -5.6, -4.2, -2.8, -1.4,  0. ,  1.4,  2.8,  4.2,  5.6,  7. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGiCAYAAAD5t/y6AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIEBJREFUeJzt3QvwVNV9B/AfD4EJ5RHLGwk2WlQe1eGhYiZgYUCs2DRmxNa0gaQYDJpYY6Iy0xplTBBSgQSItKL1EbXJiGk6EgWxpD5AbDBBRpCQFIiiQBADSHgZtnNuupv/3yCRhyznv5/PzJm7e+/Zu+fu/w/7/Z97zr2NIqIUAAAZaVztBgAAHCoBBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgBo2AHmK1/5SpRKpXpl1apVle3NmzePmTNnxpYtW2LHjh3x8MMPR4cOHerto1u3bvHoo4/Gzp07Y9OmTTFlypRo0qRJvTqDBw+OZcuWxe7du2PNmjUxevToIz1OAKCBKb3X8pWvfKW0YsWKUseOHSvlj//4jyvbv/Wtb5XWr19f+vM///NS3759S4sXLy4988wzle2NGzcuvfjii6UFCxaUzjzzzNKIESNKmzdvLn31q1+t1Dn55JNLb731Vumf//mfS6effnrpqquuKu3bt680fPjw99xORVEURVGioZdDCzA//vGPD7itdevWpT179pQ+8YlPVNaddtpppeScc84pnqfA8vbbb5c6dOhQqTNu3LjSr371q9IJJ5xQPL/tttuKkFR33w899FDpscceq/YHpSiKoihKHB+l6aF21/zpn/5pbNiwoTi9s2TJkpgwYUK88sor0a9fv2jWrFksXLiwUnf16tWxfv36GDhwYCxdurRYrlixIjZv3lypM3/+/Jg9e3b06tUrfvKTnxR16u6jXGf69OkHbVd673QKq64TTzwxtm7deqiHCABUUatWreK11147aJ1DCjAphIwZM6YIJp07dy7GxDz99NPRu3fv6NSpU+zZsye2bdtW7zVpnEvalqRlev7O7eVtB6vTpk2baNGiRRGcDiQFqZtvvvlQDgcAOE517dr1oCHmkALM448/XnmcelJSoEk9LKNGjYpdu3ZFNU2aNCmmTp1aL72lnqL0AaQBxQDA8a/8/f2HvrsP+RRSXam35ac//Wmceuqp8cQTTxSncFJPSd1emI4dO8bGjRuLx2l59tln19tH2l7eVl6W19Wtk/b5br0vyd69e4vyTukDEGAAoGE5ouvAtGzZMk455ZR4/fXXi2nPKUAMHTq0sr1Hjx7RvXv3YqxMkpZ9+vSJ9u3bV+oMGzasCCcrV66s1Km7j3Kd8j4AAOJQRvx+/etfLw0aNKjUvXv30sCBA4vp0GkadLt27SrTqNetW1c6//zzi2nUzz77bFHeOY368ccfL/3Zn/1ZMTV606ZNB5xGPXny5GIW0+c+97nDmkbdqlWrYgZUWlZ7pLSiKIqiKHG0v7/f+07TdOYNGzaUdu/eXXrllVeK5x/+8Icr25s3b16aOXNm6Y033ihCyNy5c4trxdTdx4c+9KHSvHnzSjt37izCTwpFTZo0qVdn8ODBpRdeeKF4n5/97Gel0aNHv58fgKIoiqIocXyU9/r93ej/HzTIQUDbt2+P1q1bGwMDAA3s+9u9kACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2mla7AQAcv25fsSRyc12fgdVuAseAHhgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMA1FaAueGGG6JUKsW0adMq65o3bx4zZ86MLVu2xI4dO+Lhhx+ODh061Htdt27d4tFHH42dO3fGpk2bYsqUKdGkSZN6dQYPHhzLli2L3bt3x5o1a2L06NFH0lQAoAE57ADTv3//GDduXCxfvrze+hRmLr744rj00kuLENKlS5d45JFHfveGjRvHvHnzolmzZnHeeecVwWTMmDExceLESp2TTz65qLNo0aI466yzYvr06TFnzpwYPnz44TYXAKj1ANOyZct44IEH4oorrog333yzsr5169bx93//9/HFL36xCB8vvPBCfPrTn46PfOQjcc455xR1Ugjp2bNn/O3f/m0Rfh5//PH4p3/6p7jqqqvihBNOKOpceeWVsXbt2vjSl74UL7/8csyaNavoybn22muP1nEDALUWYFKgSD0kTz75ZL31/fr1K3pWFi5cWFm3evXqWL9+fQwcOLB4npYrVqyIzZs3V+rMnz8/2rRpE7169arUqbuPcp3yPg4kvW+rVq3qFQCgYWp6qC+47LLLom/fvjFgwIDf29apU6fYs2dPbNu2rd76NM4lbSvXSc/fub287WB1Ushp0aJFMS7mnSZMmBA333zzoR4OANDQe2BOOumk+MY3vhGf/OQni6ByPJk0aVJxCqtcunbtWu0mAQDHQ4BJp4g6duxYjG3Zt29fUc4///z4whe+UDxOvSRpFlLqKakrvWbjxo3F47RMz9+5vbztYHVSz86Bel+SvXv3FrOe6hYAoGE6pACTxrz07t27mBlULv/zP/9TDOhNj3/0ox8VQWLo0KGV1/To0SO6d+8eS5YsKZ6nZZ8+faJ9+/aVOsOGDSvCycqVKyt16u6jXKe8DwCgth3SGJi33norXnrppXrr0rVc3njjjcr6u+66K6ZOnRpbt26N7du3x4wZM2Lx4sWxdOnSYvuCBQuKoHL//ffH9ddfX4x3ufXWW4uBwSn8JLNnz46rr746Jk+eHHfffXcMGTIkRo0aFRdddNHRO3IAoHYG8f4haarz/v37Y+7cucXppDR7aPz48ZXtadvIkSPjjjvuKHpUUgC6995746abbqrUWbduXRFW0jVlrrnmmnj11Vdj7NixRfgBAGgUEaVogNI06tQDlAb0Gg8DcHhuX5Hfqfvr+rz7JTdoON/f7oUEAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwA0LADzJVXXhnLly+Pbdu2FWXx4sUxYsSIyvbmzZvHzJkzY8uWLbFjx454+OGHo0OHDvX20a1bt3j00Udj586dsWnTppgyZUo0adKkXp3BgwfHsmXLYvfu3bFmzZoYPXr0kR4nAFCrAebVV1+NG2+8Mfr16xf9+/eP//qv/4rvf//70bNnz2L7tGnT4uKLL45LL720CCFdunSJRx555Hdv1rhxzJs3L5o1axbnnXdeEUzGjBkTEydOrNQ5+eSTizqLFi2Ks846K6ZPnx5z5syJ4cOHH83jBgAy1igiSkeygzfeeCO+/OUvF70tv/zlL+Pyyy+PuXPnFttOO+20ePnll+Pcc8+NpUuXFr01qfclBZvNmzcXdcaNGxeTJ0+O9u3bx759++K2226Liy66KPr06VN5j4ceeijatm0bF1544XtuV6tWrWL79u3RunXrojcIgEN3+4olkZvr+gysdhM4Au/1+/uwx8Ck3pTLLrssWrZsGUuWLCl6ZVLPysKFCyt1Vq9eHevXr4+BA3/7y5SWK1asqISXZP78+dGmTZvo1atXpU7dfZTrlPfxbtJ7p4OuWwCAhumQA0zv3r2LRLRnz56YPXt2fPzjH49Vq1ZFp06dinVpbExdaZxL2pakZXr+zu3lbQerk0JOixYt3rVdEyZMKBJbuWzYsOFQDw0AaKgBJvWqpLEp55xzTtxxxx1x7733xhlnnBHVNmnSpKK7qVy6du1a7SYBAO+Tpof6gjRO5ec//3nx+IUXXogBAwbENddcE9/5zneKWUipp6RuL0zHjh1j48aNxeO0PPvss+vtL20vbysvy+vq1kn7TLOS3s3evXuLAgA0fEd8HZg0FiYFlzTtOQWIoUOHVrb16NEjunfvXoyRSdIyDc5NA3bLhg0bVoSTlStXVurU3Ue5TnkfAACH1APzta99LR577LH4xS9+UQySTTOOzj///LjggguKcSd33XVXTJ06NbZu3Vo8nzFjRnGtmDQDKVmwYEERVO6///64/vrri/Eut956a8yaNavSe5LG1Vx99dXFzKS77747hgwZEqNGjSpmJgEAHHKASRelu++++6Jz585Fr8mLL75YhJfyrKFrr7029u/fX0yjTr0yafbQ+PHjK69P20aOHFmMnUk9KulidmkMzU033VSps27duiKspGvKpFNT6dozY8eOLcIPAMBRuQ7M8cp1YACOnOvA0OCuAwMAUC0CDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACAhh1gbrzxxnj++edj+/btsWnTpvje974XPXr0qFenefPmMXPmzNiyZUvs2LEjHn744ejQoUO9Ot26dYtHH300du7cWexnypQp0aRJk3p1Bg8eHMuWLYvdu3fHmjVrYvTo0UdynABArQaYFCpmzZoV5557bgwbNixOOOGEWLBgQXzgAx+o1Jk2bVpcfPHFcemllxb1u3TpEo888sjv3rBx45g3b140a9YszjvvvCKYjBkzJiZOnFipc/LJJxd1Fi1aFGeddVZMnz495syZE8OHDz9axw0AZKxRRJQO98Xt2rWLX/7ylzFo0KB4+umno3Xr1sXzyy+/PObOnVvUOe200+Lll18uQs/SpUtjxIgRRe9LCjabN28u6owbNy4mT54c7du3j3379sVtt90WF110UfTp06fyXg899FC0bds2LrzwwvfUtlatWhU9RalNqScIgEN3+4olkZvr+gysdhM4Au/1+/uIxsC0adOmWG7durVY9uvXr+hZWbhwYaXO6tWrY/369TFw4G9/odJyxYoVlfCSzJ8/v9hXr169KnXq7qNcp7yPA0nvmw66bgEAGqbDDjCNGjUqTu0888wz8dJLLxXrOnXqFHv27Ilt27bVq5vGuaRt5Trp+Tu3l7cdrE4KOS1atDhgeyZMmFAktnLZsGHD4R4aANBQA0waC9O7d+/467/+6zgeTJo0qehuKpeuXbtWu0kAwPuk6eG8aMaMGTFy5Mhi7Evdno6NGzcWs5BST0ndXpiOHTsW28p1zj777Hr7S9vL28rL8rq6ddI+06ykA9m7d29RAICGr/HhhJePf/zjMWTIkFi3bl29bWnacwoRQ4cOraxL06y7d+8eS5b8diBYWqbBuWnAblma0ZTCycqVKyt16u6jXKe8DwCgtjU91NNGaYbRxz72sWJkcLmXpNwzksae3HXXXTF16tRiYG96ngLP4sWLixlISZp2nYLK/fffH9dff30x3uXWW28t9l3uQZk9e3ZcffXVxcyku+++uwhLo0aNKmYmAQAcUg/M+PHji6nM//3f/12c5imXyy67rFLn2muvLaZJp2nUTz31VLH9kksuqWzfv39/cfrpN7/5TdGj8u1vfzvuu+++uOmmmyp1Us9OCiup12X58uVx3XXXxdixY4vwAwBwRNeBOZ65DgzAkXMdGBrkdWAAAKpBgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGSnabUbAFArbl+xpNpNgAZDDwwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZcTdqABqUHO/6fV2fgdVuQnb0wAAA2RFgAIDsCDAAQHYEGAAgOwIMAJAdAQYAaPgB5qMf/Wj853/+Z2zYsCFKpVJ87GMf+706t9xyS7z22mvx61//Op544ok49dRT623/4Ac/GN/+9rdj27Zt8eabb8acOXOiZcuW9er06dMnnnrqqdi1a1f84he/iC9/+cuHc3wAQAN0yAEmBY3ly5fHVVdddcDt119/fXzhC1+IK6+8Ms4555zYuXNnzJ8/P5o3b16p88ADD0SvXr1i2LBhMXLkyBg0aFD867/+a2V7q1atYsGCBbF+/fro169fEV5uvvnmuOKKKw73OAGABqRRRJQO98WpB+av/uqv4vvf/35lXep5uf3224uStG7dOjZt2hRjxoyJ73znO3H66afHqlWron///rFs2bKizgUXXBA/+MEP4qSTTorXX3+9CD9f/epXo1OnTrFv376izqRJk4r3OuOMM95T21II2r59e/H+O3bsONxDBKjpC6xxbLiQ3aF/fx/VMTB/8id/Ep07d46FCxdW1qVGLF26NAYO/O0PJy3TaaNyeElS/f379xc9NuU66fRRObwkqRcnhZ+2bdse8L2bNWtWHHTdAgA0TEc1wKQekyT1uNSVnpe3peXmzZvrbf/Nb34TW7durVfnQPuo+x7vNGHChCIslUsaowMANEwNZhZSOsWUupvKpWvXrtVuEgCQQ4DZuHFjsezYsWO99el5eVtadujQod72Jk2axIknnlivzoH2Ufc93mnv3r3FubK6BQBomI5qgFm7dm0xCHfo0KGVdWksShrbsmTJbwevpWWaRt23b99KnSFDhkTjxo2LsTLlOmlmUtOmv7tZdpqx9PLLL8evfvWro9lkAKBWplGfeeaZRSkP3E2Pu3XrVjyfPn16/OM//mNcfPHF0bt377jvvvuKmUn/8R//UWxPIeSxxx6LO++8MwYMGBDnnXdezJw5M/793/+9CD/Jgw8+WPSo3HXXXdGzZ88YNWpUXHPNNTF16tSje/QAQJZ+18XxHqXpzz/84Q8rz6dNm1Ys77nnnvj0pz8dU6ZMKUJOuq5LmjH0zDPPxIgRI2LPnj2V13zyk58sQsuTTz5ZzD6aO3duce2YsjQId/jw4TFr1qxittKWLVti4sSJRegBADii68Acz1wHBjjeuA4M78Z1YKp8HRgAgGNBgAEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAAAN/2aOcCzleO8Y9zQBeP/pgQEAsiPAAADZEWAAgOwIMABAdgQYACA7AgwAkB0BBgDIjgADAGRHgAEAsiPAAADZEWAAgOwIMABAdtzMEchSjjf6BI4ePTAAQHYEGAAgOwIMAJAdAQYAyI4AAwBkR4ABALIjwAAA2RFgAIDsuJAdHGU5XmDtuj4Dq90EgEOiBwYAyI4AAwBkR4ABALIjwAAA2RFgAIDsCDAAQHYEGAAgOwIMAJAdAQYAyI4AAwBkR4ABALIjwAAA2XEzxxqR4w0GAeDd6IEBALIjwAAA2RFgAIDsGAMDGCMFVZbjv8Hr+gys6vvrgQEAsiPAAADZEWAAgOwYA1Mj5yoBoCHRAwMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAMjOcR1gxo8fH2vXro1du3bFc889FwMGDKh2kwCA48BxG2BGjRoVU6dOjVtuuSX69u0by5cvj/nz50f79u2r3TQAoMqO2wDzxS9+Me6888645557YtWqVXHllVfGr3/96/jMZz5T7aYBAFV2XN4L6YQTToh+/frFpEmTKutKpVIsXLgwBg4ceMDXNGvWLJo3b1553qpVq3rLo6lZ4yZHfZ8AkJNW78P366Hs97gMMO3atYumTZvGpk2b6q1Pz08//fQDvmbChAlx8803/976DRs2vG/tBIBadfX27e/r/lOQ2bFjR14B5nCk3po0ZqauE088MbZu3RoNTfqhpmDWtWvXg/5wGyrHX9vHn9T6Z1Drx5/U+mfQqoEffzq+11577aB1jssAs2XLlnj77bejY8eO9dan5xs3bjzga/bu3VuUuhriD/Wdx9fQj/FgHH9tH39S659BrR9/UuufwY4Gevzv5ZiOy0G8+/bti2XLlsXQoUMr6xo1alQ8X7JkSVXbBgBU33HZA5Ok00H33ntv/OhHP4rnn38+/uEf/iFatmwZ//Zv/1btpgEAVXbcBpjvfve7xTVfJk6cGJ06dYqf/OQnMWLEiNi8eXPUuj179hQDltOyFjn+2j7+pNY/g1o//qTWP4M9NX78SaM0Q7najQAAOBTH5RgYAICDEWAAgOwIMABAdgQYACA7AkwD8Bd/8Rfx3HPPFTe7TFce/t73vhe1Jt0L68c//nFxz6wzzzwzakX37t1jzpw58b//+7/Fz/9nP/tZMTMh3U+soRo/fnysXbs2du3aVfzeDxgwIGrFjTfeWFxWYvv27cWtVdK/9R49ekStuuGGG4p/89OmTYta0qVLl7j//vuLi76mf/cvvvhicf/AWiPAZO6SSy4pfpHT9XHSF/dHPvKRePDBB6PWTJky5Q9edrohSvcGa9y4cYwbNy569eoV1157bXHn9q997WvREI0aNaq4RtQtt9wSffv2jeXLl8f8+fOLSy7UgsGDB8esWbPi3HPPjWHDhhVBdcGCBfGBD3wgak3//v2L3/v0O1BL2rZtG88++2xxwdcLL7wwevbsGdddd128+eabUYvSNGolw9KkSZPSK6+8UvrMZz5T9bZUs4wYMaK0cuXK0hlnnFFKzjzzzKq3qZrlS1/6UunnP/951dvxfpTnnnuuNGPGjMrzRo0alV599dXSDTfcUPW2VaO0a9eu+J3/6Ec/WvW2HMvSsmXL0urVq0tDhw4tLVq0qDRt2rSqt+lYlUmTJpWeeuqpqrfjeCh6YDKW/gI96aSTYv/+/fHCCy8UPRA/+MEPir/Ea0WHDh3izjvvjL/7u78rulKJaNOmTYO8iWnqbUjd5AsXLqysS6cP0vOBAwdGrf6sk4b48z6Y1As1b968ePLJJ6PW/OVf/mVxhfrvfve7xWnE9H//2LFjoxYJMBn78Ic/XCzTmIdbb701Ro4cWXQj/vCHP4wPfvCDUQvuueeemD17dnHvLCJOOeWU+PznPx//8i//Eg1Nu3btomnTpsV/2nWl5+lq3bUm3R9u+vTp8cwzz8RLL70UteKyyy4r/nibMGFC1Or/+5/73OdizZo1ccEFF8Qdd9wR3/zmN+NTn/pU1KKqdwMpv99F+Iecdtpppb/5m78pHl9xxRWV1zZr1qy0efPm0mc/+9kGf/yf//znS08//XSpcePGxeu6d+/eYE4hvdfPoO5runTpUlqzZk3pzjvvrHr734/SuXPn4rjPPffceusnT55cnFqqdvuOdfnWt75VWrt2balr165Vb8uxKieddFJp48aNpT59+lTW1doppD179pSeffbZeuu+8Y1vlBYvXlz1th3rctzeC6mW3X777UXPwsGkWSedO3cuHq9cubKyfu/evcW2D33oQ9HQj3/IkCHFqYN33gskda8+8MADMWbMmGjon0FZ+l1YtGhRLF68OD772c9GQ5RmXLz99tvRsWPHeuvT840bN0YtmTFjRtHjOmjQoNiwYUPUinQKMf2802mTstQrlz6Hq6++Opo3b16cUm/IXn/99Xr/5yerVq2KT3ziE1GLqp6ilMMrrVq1Ku3ataveIN6mTZsWf6HU7ZVpqKVbt26lXr16VcqwYcOKv9AvueSSmvqrNPW8pAGNDz74YKU3qqGW1NPyzW9+s94g3jSQvZYG8aZBzGng8qmnnlr1thzr8kd/9Ef1/s2n8vzzz5fuu+++4nG123csygMPPPB7g3inTp36e70yNVKq3gDlCErqOk3/gacv7x49ehSnD1KAadu2bdXbdqxLQzqFdCjh5ac//WnpiSeeKB537NixUqrdtvejjBo1qgjtn/rUp0qnn356afbs2aWtW7eWOnToUPW2HYsya9as0ptvvlkaNGhQvZ91ixYtqt62apVaO4XUv3//0t69e0sTJkwonXLKKcVQgrfeeqt0+eWXV71tVShVb4ByBCX1uHz9618vQsu2bdtKCxYsKPXs2bPq7apGqcUAM3r06HcdI1Pttr1f5aqrriqtW7eutHv37qJH5uyzz656m45VeTfp96DabatWqbUAk8pFF11UevHFF4swny4hMXbs2Kq3qRql0f8/AADIhmnUAEB2BBgAIDsCDACQHQEGAMiOAAMAZEeAAQCyI8AAANkRYACA7AgwAEB2BBgAIDsCDACQHQEGAIjc/B8bGYEDIe6kPgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "enemy = RandomPlayer(random.randint(0, 20000))\n",
    "# enemy = QLearning(\"90_52_1_9130.pth\", [90, 52, 1])\n",
    "\n",
    "for i in range(10000):\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(target_net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\t# while board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t# \tboard.make_move(*enemy.decide_move(board))\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\t\n",
    "\tresult = (1 if board.game_state == GameState(-1) else -1) * abs(pieces)\n",
    "\t\n",
    "\tstats.append(result)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8078"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x in stats if x > 0) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"dqn80_stats.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.0142)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
