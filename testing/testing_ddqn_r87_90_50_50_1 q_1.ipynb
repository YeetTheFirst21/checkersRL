{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState, MoveResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_SIGN = -1\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t50,\n",
    "\t\t\t50,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayer = nn.Linear(prev_size, cur_size)\n",
    "\t\t\t# nn.init.kaiming_uniform(layer.weight, nonlinearity='relu')\n",
    "\t\t\tlayers.append(layer)\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(\n",
    "\t\t\tdevice,\n",
    "\t\t\tboard.turn_sign != DEPLOYMENT_SIGN\n",
    "\t\t)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_result_to_reward(move_result: MoveResult) -> float:\n",
    "    return move_result.captured + move_result.promoted * 2\n",
    "\n",
    "def state_to_reward(state: Board) -> float:\n",
    "\treturn -2 * (state.moves_since_last_capture > 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([\n",
    "\t\t\t\tmove_result_to_reward(next_state.make_move(s, e)) + \n",
    "\t\t\t\tstate_to_reward(next_state)\n",
    "\t\t\t], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.05001 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.006 # update rate\n",
    "LR = 1e-4 # AdamW learning rate\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(dqn: DQN, board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(dqn, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer, current_step: int) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\n",
    "\treward = move_result_to_reward(state.make_move(*action)) + state_to_reward(state)\n",
    "\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\treward -= move_result_to_reward(state.make_move(*enemy.decide_move(state)))\n",
    "\n",
    "\t# if current_step > 10 and not we_captured:\n",
    "\t# \treward -= 2\n",
    "\t\t\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_105132\\153205094.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_net.load_state_dict(torch.load(\"ddqn87 90 50 50 1 q_1 tuned on ddqn86.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.0000e+00, 1.6650e+03, 4.9980e+03, 1.6680e+03, 0.0000e+00,\n",
       "        0.0000e+00, 6.6600e+03, 3.3340e+03, 6.6760e+03, 2.4998e+04]),\n",
       " array([-5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.,  5.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "test_net = DQN()\n",
    "test_net.load_state_dict(torch.load(\"ddqn87 90 50 50 1 q_1 tuned on ddqn86.pth\"))\n",
    "\n",
    "enemy = RandomPlayer(random.randint(0, 20000))\n",
    "# enemy = QLearning(\"90_52_1_9130.pth\", [90, 52, 1])\n",
    "\n",
    "for i in range(50000):\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(test_net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\t# while board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t# \tboard.make_move(*enemy.decide_move(board))\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\t\n",
    "\tresult = (1 if board.game_state == GameState(-1) else -1) * abs(pieces)\n",
    "\t\n",
    "\tstats.append(result)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83336"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x in stats if x > 0) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"dqn86_90_50_50_1_stats.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.33366"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
