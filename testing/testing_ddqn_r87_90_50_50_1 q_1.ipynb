{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState, MoveResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_SIGN = -1\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t50,\n",
    "\t\t\t50,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayer = nn.Linear(prev_size, cur_size)\n",
    "\t\t\t# nn.init.kaiming_uniform(layer.weight, nonlinearity='relu')\n",
    "\t\t\tlayers.append(layer)\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(\n",
    "\t\t\tdevice,\n",
    "\t\t\tboard.turn_sign != DEPLOYMENT_SIGN\n",
    "\t\t)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_result_to_reward(move_result: MoveResult) -> float:\n",
    "    return move_result.captured + move_result.promoted * 2\n",
    "\n",
    "def state_to_reward(state: Board) -> float:\n",
    "\treturn -2 * (state.moves_since_last_capture > 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([\n",
    "\t\t\t\tmove_result_to_reward(next_state.make_move(s, e)) + \n",
    "\t\t\t\tstate_to_reward(next_state)\n",
    "\t\t\t], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.05001 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.006 # update rate\n",
    "LR = 1e-4 # AdamW learning rate\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(dqn: DQN, board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(dqn, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer, current_step: int) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\n",
    "\treward = move_result_to_reward(state.make_move(*action)) + state_to_reward(state)\n",
    "\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\treward -= move_result_to_reward(state.make_move(*enemy.decide_move(state)))\n",
    "\n",
    "\t# if current_step > 10 and not we_captured:\n",
    "\t# \treward -= 2\n",
    "\t\t\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_98524\\1476395714.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_net.load_state_dict(torch.load(\"ddqn87 90 50 50 1 q_1 tuned on ddqn86.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  753.,  2446.,  7095.,  2554.,   900.,  2655., 24108., 18540.,\n",
       "        10906.,    43.]),\n",
       " array([-7. , -5.5, -4. , -2.5, -1. ,  0.5,  2. ,  3.5,  5. ,  6.5,  8. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "test_net = DQN()\n",
    "test_net.load_state_dict(torch.load(\"ddqn87 90 50 50 1 q_1 tuned on ddqn86.pth\"))\n",
    "\n",
    "# enemy = QLearning(\"90_52_1_9130.pth\", [90, 52, 1])\n",
    "\n",
    "for i in range(70000):\n",
    "\tenemy = RandomPlayer(i)\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(test_net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\t# while board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t# \tboard.make_move(*enemy.decide_move(board))\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\t\n",
    "\tresult = (1 if board.game_state == GameState(-1) else -1) * abs(pieces)\n",
    "\t\n",
    "\tstats.append(result)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8036"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x in stats if x > 0) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./testing/ddqn87 90 50 50 1 q_1 tuned on ddqn86_stats.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1411714285714285"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
