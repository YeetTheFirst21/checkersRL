{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t50,\n",
    "\t\t\t50,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayers.append(nn.Linear(prev_size, cur_size))\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(device)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\twe_captured = state.make_move(*action) * cur_sign\n",
    "\treward = 0\n",
    "\n",
    "\tfor pos, piece in state:\n",
    "\t\tif (cur_sign == 1 and piece == 2 and pos[1] > 3) or \\\n",
    "\t\t\t(cur_sign == -1 and piece == -2 and pos[1] < 2):\n",
    "\t\t\treward -= 1\n",
    "\n",
    "\tenemy_captured = 0\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\tenemy_captured += state.make_move(*enemy.decide_move(state)) * cur_sign * (-1)\n",
    "\t\t\n",
    "\treward += we_captured - enemy_captured\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([next_state.make_move(s, e) * next_state.turn_sign], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_353580\\1356497474.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy_net.load_state_dict(torch.load(\"dqn.pth\"))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.9 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.009 # update rate\n",
    "LR = 1e-2 # AdamW learning rate\n",
    "\n",
    "policy_net = DQN().to(device) # to be updated often\n",
    "target_net = DQN().to(device) # to be updated with TAU\n",
    "policy_net.load_state_dict(torch.load(\"dqn.pth\"))\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(policy_net, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 175.,  292.,  756.,  465.,  234.,  582., 1336., 4766., 1162.,\n",
       "         232.]),\n",
       " array([-7. , -5.6, -4.2, -2.8, -1.4,  0. ,  1.4,  2.8,  4.2,  5.6,  7. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "enemy = RandomPlayer(random.randint(0, 20000))\n",
    "# enemy = QLearning(\"90_52_1_9130.pth\", [90, 52, 1])\n",
    "\n",
    "for i in range(10000):\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(target_net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\t# while board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t# \tboard.make_move(*enemy.decide_move(board))\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\t\n",
    "\tresult = (1 if board.game_state == GameState(-1) else -1) * abs(pieces)\n",
    "\t\n",
    "\tstats.append(result)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8078"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x in stats if x > 0) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"dqn_stats.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
