{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo.dynamicProgramming import dynamicPlayer\n",
    "from algo.iplayer import RandomPlayer, IPlayer\n",
    "from algo.q_learning import QLearning\n",
    "from algo.board import Board, GameState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    # \"cuda\" if torch.cuda.is_available() else\n",
    "    # \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tUsing structure similar to NNUE:\n",
    "\thttps://www.chessprogramming.org/File:StockfishNNUELayers.png\n",
    "\t\n",
    "\tObservation space: hot-encoded board:\n",
    "\tfor each of 18 cells we can be -2, -1, 0, 1, 2 (5 possibilities).\n",
    "\tIn total it gives 18 * 5 = 90 possible inputs, out of which at most 12 are on.\n",
    "\t\n",
    "\t# Action space: 4 possible actions.\n",
    "\tValue function: 1 output. # https://www.reddit.com/r/reinforcementlearning/comments/1b1te73/help_me_understand_why_use_a_policy_net_instead/\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\n",
    "\t\tlayer_sizes = [\n",
    "\t\t\t90,\n",
    "\t\t\t52,\n",
    "\t\t\t1\n",
    "\t\t]\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tprev_size = layer_sizes[0]\n",
    "\t\tfor cur_size in layer_sizes[1:]:\n",
    "\t\t\tlayers.append(nn.Linear(prev_size, cur_size))\n",
    "\t\t\tprev_size = cur_size\n",
    "\n",
    "\t\tself.layers = nn.ModuleList(layers)\n",
    "\n",
    "\tdef forward(self, board: Board) -> torch.Tensor:\n",
    "\t\tstate = board.to_tensor(device)\n",
    "\t\tfor layer in self.layers[:-1]:\n",
    "\t\t\tstate = F.relu(layer(state))\n",
    "\t\treturn self.layers[-1](state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_environment_step(state: Board, action: tuple[tuple[int, int], tuple[int, int]], enemy: IPlayer) -> tuple[Board, torch.Tensor]:\n",
    "\t\"\"\"\n",
    "\tReturns new state and reward for the given action.\n",
    "\t\"\"\"\n",
    "\tstate = copy.deepcopy(state)\n",
    "\tcur_sign = state.turn_sign\n",
    "\twe_captured = state.make_move(*action) * cur_sign\n",
    "\treward = 0\n",
    "\n",
    "\tfor pos, piece in state:\n",
    "\t\tif (cur_sign == 1 and piece == 2 and pos[1] > 3) or \\\n",
    "\t\t\t(cur_sign == -1 and piece == -2 and pos[1] < 2):\n",
    "\t\t\treward -= 1\n",
    "\n",
    "\tenemy_captured = 0\n",
    "\twhile state.game_state == GameState.NOT_OVER and state.turn_sign != cur_sign:\n",
    "\t\tenemy_captured += state.make_move(*enemy.decide_move(state)) * cur_sign * (-1)\n",
    "\t\t\n",
    "\treward += we_captured - enemy_captured\n",
    "\tif state.game_state != GameState.NOT_OVER:\n",
    "\t\tour_pieces = 0\n",
    "\t\tenemy_pieces = 0\n",
    "\t\tfor _, piece in state:\n",
    "\t\t\tif piece == cur_sign:\n",
    "\t\t\t\tour_pieces += 1\n",
    "\t\t\telif piece == -cur_sign:\n",
    "\t\t\t\tenemy_pieces += 1\n",
    "\t\t\telif piece == 2 * cur_sign:\n",
    "\t\t\t\tour_pieces += 2\n",
    "\t\t\telif piece == -2 * cur_sign:\n",
    "\t\t\t\tenemy_pieces += 2\n",
    "\t\t\t\n",
    "\t\treward += 3 * our_pieces / (enemy_pieces + 1)\n",
    "\n",
    "\t\tif state.game_state == GameState.DRAW:\n",
    "\t\t\treward -= 40\n",
    "\t\telif state.game_state == GameState(cur_sign):\n",
    "\t\t\treward += 40\n",
    "\t\telif state.game_state == GameState(-cur_sign):\n",
    "\t\t\treward -= 40\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\"Unexpected game state\")\n",
    "\t\n",
    "\treturn state, torch.Tensor([reward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99 # discount rate\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "\taction: tuple[tuple[int, int], tuple[int, int]]\n",
    "\tvalue: torch.Tensor\n",
    "\n",
    "def q_s(dqn: DQN, current_state: Board) -> list[Action]:\n",
    "\t\"\"\"\n",
    "\tReturn: list[(new_state, action, immediate_reward, value)]\n",
    "\t\"\"\"\n",
    "\tret: list[Action] = []\n",
    "\tfor s in current_state.get_possible_pos():\n",
    "\t\tfor e in current_state.get_correct_moves(s):\n",
    "\t\t\tnext_state = copy.deepcopy(current_state)\n",
    "\t\t\timmediate_reward = torch.tensor([next_state.make_move(s, e) * next_state.turn_sign], device=device)\n",
    "\t\t\tvalue = dqn(next_state) * GAMMA + immediate_reward\n",
    "\t\t\tret.append(Action((s, e), value))\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_354668\\3647971076.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy_net.load_state_dict(torch.load(\"90_52_1_9130.pth\"))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50 # number of transitions sampled from the replay buffer\n",
    "\n",
    "EPS_START = 0.9 # exploration rate\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.009 # update rate\n",
    "LR = 1e-2 # AdamW learning rate\n",
    "\n",
    "policy_net = DQN().to(device) # to be updated often\n",
    "target_net = DQN().to(device) # to be updated with TAU\n",
    "policy_net.load_state_dict(torch.load(\"90_52_1_9130.pth\"))\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(board: Board) -> Action:\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "\t\tmath.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tstate_values = q_s(policy_net, board)\n",
    "\t\t\treturn max(state_values, key=lambda x: x.value.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tpossible_moves = []\n",
    "\t\tfor s in board.get_possible_pos():\n",
    "\t\t\tfor e in board.get_correct_moves(s):\n",
    "\t\t\t\tpossible_moves.append((s, e))\n",
    "\t\treturn Action(\n",
    "\t\t\trandom.choice(possible_moves),\n",
    "\t\t\ttorch.tensor([0], device=device)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 356.,  711.,  356.,  716.,    0., 1066., 1074., 2498., 1792.,\n",
       "        1431.]),\n",
       " array([-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "enemy = RandomPlayer(random.randint(0, 20000))\n",
    "# enemy = QLearning(\"90_52_1_9130.pth\", [90, 52, 1])\n",
    "\n",
    "for i in range(10000):\n",
    "\tboard = Board()\n",
    "\twhile board.game_state == GameState.NOT_OVER:\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == 1:\n",
    "\t\t\tboard.make_move(*enemy.decide_move(board))\n",
    "\t\twhile board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tstate_values = max(q_s(target_net, board), key=lambda x: x.value.item())\n",
    "\t\t\t\tboard.make_move(*state_values.action)\n",
    "\t\t# while board.game_state == GameState.NOT_OVER and board.turn_sign == -1:\n",
    "\t\t# \tboard.make_move(*enemy.decide_move(board))\n",
    "\t\n",
    "\tpieces = 0\n",
    "\tfor _, piece in board:\n",
    "\t\tpieces += piece != 0\n",
    "\t\n",
    "\tresult = (1 if board.game_state == GameState(-1) else -1) * abs(pieces)\n",
    "\t\n",
    "\tstats.append(result)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7861"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x in stats if x > 0) / len(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"dqn_y91_90_52_1.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.0052)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stats) / len(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
